{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recommendation System for Implicit Data & Logistic Matrix Factorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Outline:\n",
    "\n",
    "1. Background\n",
    "2. Simplified Workflows.\n",
    "3. Importing Data\n",
    "4. Data Preparations\n",
    "5. Data Preprocessing\n",
    "6. Modeling\n",
    "7. Hyperparameter Tuning\n",
    "8. Evaluation\n",
    "9. Decision Process (Recommendation Process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Background**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spotify, a Steaming Music Company has a problem with their customer.\n",
    "- After 3 months from the launch of their previous recommender system, many of the user churn (20%).\n",
    "- After doing immediate research, they found that user did not consumed what spotify recommending, it means the recommendation is not working good for them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let say , you are just hired as **Data Scientist / ML Scientist** on Spotify,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Objective\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our business objective would be **decreasing user churn 20%** (assumed ofcourse) in 3 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can fix previous recommendation algorithm, instead of using star (explicit data) we are gonna use number of plays from user to each artist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using number of plays from each user to each artist give meaning to their preference, the more they play it the more confidence we can say, that they are liking those artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our task** is to predict number the preference from each user to each artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a clearer picture what we should do, However we need more precise solution in recommender system context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach in Personalized Recommender System can be divided based on the presence of interaction data (explicit / implicit) data:     \n",
    "\n",
    "1. When the interaction data is not exists, the solution that can be implemented is using content feature, **Content Based** Filtering\n",
    "\n",
    "2. When the interaction data is exists, we can use **Collaborative** Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **Implicit Recommender System** Approach to address this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Metrics\n",
    "---\n",
    "We have already established some points :\n",
    "- Our task is to predict the preference scale (0-1) from users\n",
    "- We will use Implicit Feedback Recommender System\n",
    "\n",
    "Regarding those, we need to measure the success of our model ( metrics)\n",
    "\n",
    "Previously we rely heavily on evaluating how close our predicted rating to what it supposed to be\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are lots of Disadvantage, such as :    \n",
    "1. Predicted ratings does not always correlate with what user what\n",
    "\n",
    "We need a solution ? Why don't we just give relevant item recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our focus, is that we want user receive most relevant item since user has limited time to listen to music,\n",
    "we will use **Precision @ K** as our metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data is obtained from [Heatrec Dataset](https://grouplens.org/datasets/hetrec-2011/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one file we use\n",
    "\n",
    "**song count data** : `user_artist_play.csv`\n",
    "\n",
    "\n",
    "|Features|Descriptions|Data Type|\n",
    "|:--|:--|:--:|\n",
    "|`userID`|The user ID|`object`|\n",
    "|`artistID`|artist that user listen to |`int`|\n",
    "|`weight`|Number of Plays |`int`|\n",
    "\n",
    "\n",
    "**artist name** : `artist_name.csv`\n",
    "\n",
    "\n",
    "\n",
    "|Features|Descriptions|Data Type|\n",
    "|:--|:--|:--:|\n",
    "|`id`|artist ID|`object`|\n",
    "|`name`|artist name|`int`|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Recommender System Workflow** (Simplified)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='white'>1. Importing Data</font>\n",
    "\n",
    "```\n",
    "1. Load the data.\n",
    "2. Check the shape & type of data.\n",
    "3. Handle the duplicates data to maintain data validity.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='white'>2.Modelling : Implicit Feedback Recommender</font>\n",
    "\n",
    "```\n",
    "1. Creating Utility Matrix\n",
    "2. Training + Model Selection  :     \n",
    "    - Alternating least Squares\n",
    "    - Logistic Matrix Factorization\n",
    "\n",
    "4. Evaluating Model\n",
    "  - Precision @ 5\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='white'>3. Generating Recommendation / Predictions</font>\n",
    "\n",
    "```\n",
    "1. Giving recommendation for user\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Importing Data**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we do?\n",
    "1. Load the data.\n",
    "2. Check the shape & type of data.\n",
    "3. Handle the duplicates data to maintain data validity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load this library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>325</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>191</td>\n",
       "      <td>4259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>344</td>\n",
       "      <td>5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>519</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>609</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  weight\n",
       "0       7       325     599\n",
       "1      12       191    4259\n",
       "2      12       344    5489\n",
       "3      12       519     982\n",
       "4      15       609     407"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_play_path = '../data/sample_user_artist.csv'\n",
    "\n",
    "song_play_data = pd.read_csv(song_play_path,\n",
    "                          delimiter = ',')\n",
    "\n",
    "song_play_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check data shapes & types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data shapes\n",
    "song_play_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_play_data.userID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userID      int64\n",
       "artistID    int64\n",
       "weight      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data types\n",
    "song_play_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling duplicates data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to check that there is no user ID that rates similar movie ID more than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicate data\n",
    "song_play_data.duplicated(subset=['userID', 'artistID']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create load function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create load data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_song_data(path):\n",
    "    \"\"\"\n",
    "    Function to load data & remove from duplicates\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        The path of song play  data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    song_play_data : pandas DataFrame\n",
    "        The sample of song play data\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    song_play_data = pd.read_csv(path, delimiter=',')\n",
    "    print('Original data shape :', song_play_data.shape)\n",
    "\n",
    "\n",
    "    return song_play_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape : (150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load rating data\n",
    "song_play_data = load_song_data(path = song_play_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>325</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>191</td>\n",
       "      <td>4259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>344</td>\n",
       "      <td>5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>519</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>609</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  weight\n",
       "0       7       325     599\n",
       "1      12       191    4259\n",
       "2      12       344    5489\n",
       "3      12       519     982\n",
       "4      15       609     407"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_play_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Modelling**: Implicit Feedback Recommender System\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a personalized RecSys, we can follow these steps:\n",
    "\n",
    "```\n",
    "1. Data Preparation --> Create utility matrix & Split Train-Test\n",
    "2. Train recommendation model --> Baseline, Alternating Least Squares, Logistic Matrix Factorization\n",
    "3. Choosing Best Model\n",
    "5. Evaluate Final Model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Model From Scratch\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping User and Item ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create mapping, we can simply create dictionary, which stores :    \n",
    "- UserId to ordered id\n",
    "```python\n",
    "user_to_id = {userid : orderedid}\n",
    "#example\n",
    "user_to_id = {'ab' : 1}\n",
    "```\n",
    "- Ordered id to UserId\n",
    "```python\n",
    "user_to_id = {orderedid : userid }\n",
    "#example\n",
    "user_to_id = {1 : 'ab' }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping user to ordered id\n",
    "user_to_id = {user : idx for idx,user in enumerate(song_play_data['userID'].unique())}\n",
    "id_to_user = {idx : user for idx,user in enumerate(song_play_data['userID'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping item to ordered id\n",
    "item_to_id = {item : idx for idx,item in enumerate(song_play_data['artistID'].unique())}\n",
    "id_to_item = {idx : item for idx,item in enumerate(song_play_data['artistID'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_data = song_play_data.copy()\n",
    "mapped_data['userID'] = mapped_data['userID'].map(user_to_id)\n",
    "mapped_data['artistID'] = mapped_data['artistID'].map(item_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>6933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>11498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>97</td>\n",
       "      <td>24</td>\n",
       "      <td>2120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>98</td>\n",
       "      <td>67</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>98</td>\n",
       "      <td>68</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID  artistID  weight\n",
       "0         0         0     599\n",
       "1         1         1    4259\n",
       "2         1         2    5489\n",
       "3         1         3     982\n",
       "4         2         4     407\n",
       "..      ...       ...     ...\n",
       "145      97         0    6933\n",
       "146      97         2   11498\n",
       "147      97        24    2120\n",
       "148      98        67     212\n",
       "149      98        68      87\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create function to map the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data(data, user_column, item_column) :\n",
    "    \"\"\"\n",
    "    Function to map user and item ID for given dataframe\n",
    "\n",
    "    Paramaters:\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        dataframe to be mapped its ID (user and item)\n",
    "\n",
    "    user_column : string\n",
    "        user id to be mapped\n",
    "\n",
    "    item_column : string\n",
    "        item id to be mapped\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    mapped_data : pandas.DataFrame\n",
    "\n",
    "    mapping_user: dict\n",
    "        dictionary contain user_to_id and id_to_user mapping\n",
    "    mapping_item :\n",
    "        dictionary contain item_to_id and id_to_item mapping\n",
    "\n",
    "    \"\"\"\n",
    "    # mapping user to ordered id\n",
    "    user_to_id = {user : idx for idx,user in enumerate(data[user_column].unique())}\n",
    "\n",
    "    id_to_user = {idx : user for idx,user in enumerate(data[user_column].unique())}\n",
    "\n",
    "    # mapping item to ordered id\n",
    "    item_to_id = {item : idx for idx,item in enumerate(data[item_column].unique())}\n",
    "\n",
    "    id_to_item = {idx : item for idx,item in enumerate(data[item_column].unique())}\n",
    "\n",
    "    # copy data to avoid overwriting\n",
    "    mapped_data = data.copy()\n",
    "\n",
    "    mapped_data[user_column] = mapped_data[user_column].map(user_to_id)\n",
    "    mapped_data[item_column] = mapped_data[item_column].map(item_to_id)\n",
    "\n",
    "    # create mapping\n",
    "    mapping_user = {'user_to_id' : user_to_id,'id_to_user' : id_to_user}\n",
    "    mapping_item = {'item_to_id' : item_to_id,'id_to_item' : id_to_item}\n",
    "\n",
    "    return mapped_data,mapping_user,mapping_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  weight\n",
       "0       0         0     599\n",
       "1       1         1    4259\n",
       "2       1         2    5489\n",
       "3       1         3     982\n",
       "4       2         4     407"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_playdata_mapped,mapping_user,mapping_item = map_data(data= song_play_data,\n",
    "                                user_column = 'userID',\n",
    "                                item_column = 'artistID')\n",
    "song_playdata_mapped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternating Least Squares\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Objective}= \\underset{}{\\min}\n",
    "\\left [\n",
    " \\sum_{u \\in U} \\sum_{n \\in I}(p_{ui}^{(n)} - \\hat{p_{ui}}^{(n)})^2\n",
    "\\right ]\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "p_{ui} = \\begin{cases}\n",
    "  1 & r_{ui} > 0 \\\\\n",
    "  0 & r_{ui} < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "- $r_{ui}$ : Implicit data feedback from user u to item i\n",
    "\n",
    "Our main goal is to minimize preference error, between true preference - predicted preference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add term $\\cfrac{1}{2}$ (optional), the purpose is to make the derivative more simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Objective}= \\underset{}{\\min} \\cfrac{1}{2}\n",
    "\\left [\n",
    " \\sum_{u \\in U} \\sum_{n \\in I}(p_{ui}^{(n)} - \\hat{p_{ui}}^{(n)})^2\n",
    "\\right ]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding confidence term\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Objective}= \\underset{}{\\min} \\cfrac{1}{2}\n",
    "\\left [\n",
    " \\sum_{u \\in U} \\sum_{n \\in I} c_{ui}(p_{ui}^{(n)} - \\hat{p_{ui}}^{(n)})^2\n",
    "\\right ]\n",
    "$$\n",
    "\n",
    "- $c_{ui} = 1 + \\alpha r_{ui}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remember that to predict user preference towards item i is yielded from dot product $x_u . y_i^T$\n",
    "\n",
    "with  :     \n",
    "- $x_u$ : User u latent factor\n",
    "- $y_i$ : Item i latent factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Objective}= \\underset{x^*,y^*}{\\min} \\cfrac{1}{2}\n",
    "\\left [\n",
    " \\sum_{u \\in U} \\sum_{n \\in I} c_{ui}(p_{ui} - x_u.y_i^T)^2\n",
    "\\right ]\n",
    "$$\n",
    "\n",
    "- $c_{ui} = 1 + \\alpha r_{ui}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Regularization\n",
    "\n",
    "The purpose of adding regularization is to make our model can avoid overfitting.We can add Ridge Regularization.\n",
    "\n",
    "- We come to **Final Objective Function** as follow :\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{Objective}= \\underset{x^*,y^*}{\\min} \\cfrac{1}{2}\n",
    "\\left [\n",
    " \\sum_{u \\in U} \\sum_{n \\in I} c_{ui}(p_{ui} - x_u.y_i^T)^2\n",
    "\\right ] + \\cfrac{\\lambda}{2} \\sum_{u \\in U} \\sum_{n \\in I} \\left[  ||x_u||^2 + ||y_i||^2 \\right]\n",
    "$$\n",
    "\n",
    "- $c_{ui} = 1 + \\alpha r_{ui}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization\n",
    "\n",
    "There are two parameters in Alternating Least Squares\n",
    "- $x_u$ : User factor , matrix `<n_users x n_factor>`\n",
    "- $y_i$ : Item factor , matrix `<n_items x n_factor>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_user = song_playdata_mapped.userID.nunique()\n",
    "n_item = song_playdata_mapped.artistID.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user factor (99, 50)\n",
      "Shape of item factor (69, 50)\n"
     ]
    }
   ],
   "source": [
    "# set number of latent factor\n",
    "n_factor = 50\n",
    "\n",
    "# set seed\n",
    "np.random.seed(49)\n",
    "\n",
    "# initialize user and item factor\n",
    "xu = np.random.normal(0.,1.,size=(n_user,n_factor))\n",
    "yi = np.random.normal(0.,1.,size=(n_item,n_factor))\n",
    "\n",
    "# print shape\n",
    "print('Shape of user factor',xu.shape)\n",
    "print('Shape of item factor',yi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "from numpy.linalg import norm\n",
    "def als_loss(p_true,confidence,xu,yi,lambda_regularization) :\n",
    "    \"\"\"Function to calculate loss on Alternating Least Squares\"\"\"\n",
    "\n",
    "    original_loss = (1/2)* confidence*((p_true-(xu.dot(yi.T)))**2)\n",
    "    regularization_loss = (lambda_regularization/2)**(norm(xu)**2 + norm(yi)**2)\n",
    "\n",
    "    total_loss = original_loss + regularization_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Function\n",
    "\n",
    "Our prediction is generated from dot product between user and item factor\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{p_{ui}} = x_u \\cdot y_i^T\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xu,yi):\n",
    "    \"\"\"Prediction function for Alternating Least Squares\"\"\"\n",
    "    pred_pui = xu.dot(yi.T)\n",
    "\n",
    "    return pred_pui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### User Factor ($x_u$)\n",
    "To find user factor we can solve analytically with Alternating Least Squares\n",
    "$x_u = (Y^T.C^u.Y + \\lambda I )^{-1} \\cdot (Y^T.C^u.p(u))$\n",
    "\n",
    "with\n",
    "- $Y^T$ : Item Factor (Constant) Transposed\n",
    "- $Y$ : Item Factor (Constant)\n",
    "- $\\lambda I$ : Regularization Term multiply by identity matrix\n",
    "- $C^u$ : Confidence from user u to all item , diagonal matrix, has shape of `<n_item x n_item>`\n",
    "- $p(u)$ : preference from user u, contain binary value of preference (0/1) for all item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Item Factor ($y_i$)\n",
    "\n",
    "\n",
    "To find user factor we can solve analytically with Alternating Least Squares\n",
    "$yi = (X^T.C^i.X + \\lambda I )^{-1} \\cdot (X^T.C^i.p(i))$\n",
    "\n",
    "with\n",
    "- $X^T$ : User Factor (Constant) Transposed\n",
    "- $X$ : User Factor (Constant)\n",
    "- $\\lambda I$ : Regularization Term multiply by identity matrix\n",
    "- $C^i$ : Confidence from item i to all user , diagonal matrix, has shape of `<n_user x n_user>`\n",
    "- $p(i)$ : preference from item i contain binary value of preference (0/1) for all user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimization Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During optimization we are doing by Solving Analytical Way, called **Alternating Least Squares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "n_epoch = 3\n",
    "alpha = 1\n",
    "lambda_reg = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously Our Utility Matrix is in Form of Number of user play to each artist, However The Alternating Least Squares Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $c_{ui} = 1 + \\alpha r_{ui}$ have similar size to utility matrix `<n_users,n_items>`\n",
    "- $\n",
    "p_{ui} = \\begin{cases}\n",
    "  1 & r_{ui} > 0 \\\\\n",
    "  0 & r_{ui} < 0\n",
    "\\end{cases}  \n",
    "$ have similar size to utility matrix `<n_users,n_items>`\n",
    "\n",
    "- $r_{ui}$ : Implicit data feedback from user u to item i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.zeros(shape=(n_user,n_item))\n",
    "C = np.zeros(shape=(n_user,n_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill both Confidence and preference\n",
    "for user_id in range(n_user) :\n",
    "    for item_id in range(n_item) :\n",
    "        # retrieve true value from our dataframe\n",
    "        filter_user = song_playdata_mapped['userID']==user_id\n",
    "        filter_item = song_playdata_mapped['artistID']==item_id\n",
    "\n",
    "        r_ui = song_playdata_mapped.loc[(filter_user&filter_item),'weight']\n",
    "        if r_ui.empty :\n",
    "            r_ui = 0\n",
    "        else :\n",
    "            r_ui = r_ui.values[0]\n",
    "\n",
    "        P[user_id,item_id] = 1 if r_ui > 0 else 0\n",
    "        c_ui = 1 + alpha*(r_ui)\n",
    "        C[user_id,item_id] = c_ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output of Preference matrix after filling the data\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.0000e+02, 1.0000e+00, 1.0000e+00, ..., 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 4.2600e+03, 5.4900e+03, ..., 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 1.0000e+00, 1.0000e+00, ..., 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00],\n",
       "       ...,\n",
       "       [1.0000e+00, 1.0000e+00, 1.0000e+00, ..., 1.6600e+02, 1.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [6.9340e+03, 1.0000e+00, 1.1499e+04, ..., 1.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [1.0000e+00, 1.0000e+00, 1.0000e+00, ..., 1.0000e+00, 2.1300e+02,\n",
       "        8.8000e+01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the output of Confidence matrix after filling the data\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Our Alternating Least Squares Model, to find best parameter we do not need to iterate like gradient descent, because we find best parameter analytically through Alternating Least Squares, however we still curious comparison loss before and after finding optimal weight / parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  3.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# create container to add avg loss during each epoch\n",
    "loss_per_epoch = []\n",
    "\n",
    "for _ in tqdm(range(n_epoch)) :\n",
    "    # predict\n",
    "    pred_pui = np.dot(xu,yi.T)\n",
    "    # calculate loss (vectorized)\n",
    "    loss =  (((P - np.dot(xu,yi.T))**2).dot(C.T).sum()) / (2*(n_user*n_item))\n",
    "    regularization_loss = (lambda_reg / 2)*(norm(xu)**2 + norm(yi)**2)\n",
    "\n",
    "    total_loss = loss + regularization_loss\n",
    "\n",
    "    loss_per_epoch.append(total_loss)\n",
    "\n",
    "    # update user factor parameter\n",
    "    for user_id in range(n_user) :\n",
    "        # holding item factor constant = use all item factor\n",
    "        Yt = yi.T\n",
    "        Y = yi\n",
    "        # Confidence for user n_item x n item --> diagonalize C[user_id,:]\n",
    "        Cu = np.diag(C[user_id,:])\n",
    "        # inverse component (Y^T C^u Y + \\lambda I)\n",
    "        inv_component = np.dot(yi.T,Cu).dot(yi) + np.eye(n_factor)*lambda_reg\n",
    "        inv = np.linalg.inv(inv_component)\n",
    "\n",
    "        # non inverse component Y^T C^u p(u)\n",
    "        p_u = P[user_id,:]\n",
    "        non_inverse_component = (Yt).dot(Cu).dot(p_u)\n",
    "\n",
    "        gradient_xu = inv.dot(non_inverse_component)\n",
    "\n",
    "        # update xu\n",
    "        xu[user_id,:] = (gradient_xu)\n",
    "\n",
    "    for item_id in range(n_item) :\n",
    "        # holding user factor constant\n",
    "        Xt = xu.T\n",
    "        X = xu\n",
    "        # Confidence for item , <n_user x n_user>\n",
    "        Ci = np.diag(C.T[item_id,:])\n",
    "        # inverse component (Y^T C^u Y + \\lambda I)\n",
    "        inv_component = np.dot(Xt,Ci).dot(X) + np.eye(n_factor)*lambda_reg\n",
    "        inv = np.linalg.inv(inv_component)\n",
    "\n",
    "        # non inverse component X^T C^i p(i)\n",
    "        p_i = P.T[item_id,:]\n",
    "        non_inverse_component = (Xt).dot(Ci).dot(p_i)\n",
    "\n",
    "        gradient_yi = inv.dot(non_inverse_component)\n",
    "\n",
    "        # update xu\n",
    "        yi[item_id,:] =  (gradient_yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01018646, -0.01587455, -0.01052307, ...,  0.0417707 ,\n",
       "         0.01193571, -0.05091199],\n",
       "       [ 0.0413182 , -0.04718764, -0.01583278, ..., -0.01942131,\n",
       "         0.13075696,  0.15918287],\n",
       "       [ 0.00743091,  0.07881525,  0.0161102 , ...,  0.10976351,\n",
       "        -0.02992938, -0.02194887],\n",
       "       ...,\n",
       "       [-0.02838972, -0.0280652 ,  0.01058166, ..., -0.04582924,\n",
       "         0.00668671,  0.03542043],\n",
       "       [ 0.04245437, -0.02852866, -0.04660927, ...,  0.13365577,\n",
       "         0.0504858 , -0.00871866],\n",
       "       [ 0.01154349,  0.04739146,  0.01696743, ...,  0.0282243 ,\n",
       "         0.08266359,  0.04932873]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check optimized parameter\n",
    "xu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24066613, -0.79313493,  2.35377405, ...,  0.22474517,\n",
       "        -0.20532423, -1.28316298],\n",
       "       [-1.43687154, -1.37947515, -1.56762961, ...,  0.93692672,\n",
       "         0.22011984, -0.67401479],\n",
       "       [ 0.09705254, -0.25110156,  0.02517918, ...,  0.46950799,\n",
       "        -0.57925938,  0.29591512],\n",
       "       ...,\n",
       "       [-0.55893477,  1.77353728,  0.6004664 , ..., -1.37548306,\n",
       "         0.99006334,  0.85317887],\n",
       "       [-0.54655872,  0.63054222,  0.87974532, ..., -0.59757716,\n",
       "         1.41928795,  1.19264131],\n",
       "       [-0.54639853,  0.63035741,  0.87948748, ..., -0.59740202,\n",
       "         1.41887197,  1.19229176]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check optimized parameter\n",
    "yi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Oriented Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlternatingLeastSquares :\n",
    "    def __init__(self,n_epoch=10,n_factor=50,alpha=1,lambda_reg=0.01) :\n",
    "        \"\"\"Initialize Hyperparameter \"\"\"\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_factor = n_factor\n",
    "        self.alpha = 1\n",
    "        self.lambda_reg = 0.001\n",
    "\n",
    "\n",
    "    def prepare_confidence_preference(self,data,user_column,item_column,utility_column,n_user,n_item) :\n",
    "        \"\"\"\n",
    "        Function to user and item factor\n",
    "        Parameters :\n",
    "        -----------\n",
    "        data : pandas DataFrame\n",
    "            utility data\n",
    "        user_column : string\n",
    "            user id column name\n",
    "        item_column : string\n",
    "            item id column name\n",
    "        utility_column : string\n",
    "            explicit / implicit data column name\n",
    "        n_user : int\n",
    "          number of user\n",
    "        n_item : int\n",
    "          number of item\n",
    "\n",
    "        Returns :\n",
    "        --------\n",
    "        P : numpy matrix,\n",
    "            Binary Preference user on item (0/1) shape <n_user,n_item>\n",
    "        C : int\n",
    "            Confidence from user on item (c_{ui} = 1 + \\alpha*r_{ui}) shape <n_user,n_item>\n",
    "        \"\"\"\n",
    "        # assign zero matrix first for later we fill with our available data\n",
    "        P = np.zeros(shape=(n_user,n_item))\n",
    "        C = np.zeros(shape=(n_user,n_item))\n",
    "        # iterate all over user and item\n",
    "\n",
    "        for user_id in range(n_user) :\n",
    "          for item_id in range(n_item) :\n",
    "              # retrieve true value (r_ui) from our dataframe\n",
    "              filter_user = data[user_column]==user_id\n",
    "              filter_item = data[item_column]==item_id\n",
    "\n",
    "              r_ui = song_playdata_mapped.loc[(filter_user&filter_item),utility_column]\n",
    "\n",
    "              # if empty means --> no observation,\n",
    "              if r_ui.empty :\n",
    "                  # due to we use that as negative sample we assign r_ui = 0\n",
    "                  r_ui = 0\n",
    "              else :\n",
    "                  # else we use non zero r_ui\n",
    "                  r_ui = r_ui.values[0]\n",
    "              #\n",
    "              P[user_id,item_id] = 1 if r_ui > 0 else 0\n",
    "              c_ui = 1 + alpha*(r_ui)\n",
    "              C[user_id,item_id] = c_ui\n",
    "\n",
    "        return P,C\n",
    "\n",
    "    def fit(self,utility_data,user_column,item_column,utility_column) :\n",
    "        \"\"\"\n",
    "        Function to fit utility_data\n",
    "        Parameters :\n",
    "        -----------\n",
    "        utility_data : pandas.DataFrame\n",
    "            utility_dataframe contain user and item interaction order <userID,itemID,utility_value>\n",
    "        user_column : string\n",
    "        item_column : string\n",
    "        utility_column : string\n",
    "        Returns :\n",
    "        --------\n",
    "\n",
    "        \"\"\"\n",
    "        self.utility_data = utility_data\n",
    "        self.user_column = user_column\n",
    "        self.item_column = item_column\n",
    "        self.utility_column = utility_column\n",
    "        self.n_user = utility_data[user_column].nunique()\n",
    "        self.n_item = utility_data[item_column].nunique()\n",
    "        self.P,self.C = self.prepare_confidence_preference(data=utility_data,user_column= user_column, item_column = item_column\n",
    "                                           ,utility_column= utility_column, n_user = n_user, n_item = n_item)\n",
    "        # initialize parameter\n",
    "        xu = np.random.normal(0.,1.,size=(n_user,n_factor))\n",
    "        yi = np.random.normal(0.,1.,size=(n_item,n_factor))\n",
    "\n",
    "        # update parameter\n",
    "        self.loss_per_epoch = []\n",
    "        for _ in tqdm(range(self.n_epoch)) :\n",
    "\n",
    "            pred_pui = np.dot(xu,yi.T)\n",
    "            # calculate loss (vectorized)\n",
    "            loss =  (((P - np.dot(xu,yi.T))**2).dot(C.T).sum()) / (2*(n_user*n_item))\n",
    "            regularization_loss = (lambda_reg / 2)*(norm(xu)**2 + norm(yi)**2)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "            # append loss, for plotting\n",
    "            self.loss_per_epoch.append(total_loss)\n",
    "\n",
    "            # update user and item factor\n",
    "            xu,yi = self.update_factor(P= self.P,\n",
    "                                      C = self.C,\n",
    "                                      xu = xu,\n",
    "                                      yi= yi)\n",
    "        # save optimized user and item factor\n",
    "        self.xu = xu\n",
    "        self.yi = yi\n",
    "\n",
    "    def predict(self,userid,itemid) :\n",
    "        \"\"\"\n",
    "        Function to predict preference on user id and item id level\n",
    "        Parameters :\n",
    "        -----------\n",
    "        userid : int\n",
    "            mapped user id\n",
    "        itemid : int\n",
    "            mapped item id\n",
    "\n",
    "        Returns :\n",
    "        --------\n",
    "        predicted_preference : float\n",
    "            predicted preference score\n",
    "        \"\"\"\n",
    "        predicted_preference  = self.xu[user_id].dot(self.yi[item_id].T)\n",
    "\n",
    "        return predicted_preference\n",
    "\n",
    "    def update_factor(self,P,C,xu,yi) :\n",
    "        \"\"\"\n",
    "        Function to user and item factor\n",
    "        Parameters :\n",
    "        -----------\n",
    "        P : numpy matrix,\n",
    "            Binary Preference user on item (0/1) shape <n_user,n_item>\n",
    "        C : int\n",
    "            Confidence from user on item (c_{ui} = 1 + \\alpha*r_{ui}) shape <n_user,n_item>\n",
    "        xu : numpy matrix,\n",
    "            User factor , shape <n_user,n_factor>\n",
    "        yi : numpy matrix,\n",
    "            Item factor , shape <n_item,n_factor>\n",
    "        Returns :\n",
    "        --------\n",
    "        xu : numpy matrix,\n",
    "            Optimzed User factor , shape <n_user,n_factor>\n",
    "        yi : numpy matrix,\n",
    "            Optimized Item factor , shape <n_item,n_factor>\n",
    "        \"\"\"\n",
    "        # iterate all over user to update user factor\n",
    "        for user_id in range(self.n_user) :\n",
    "            # holding item factor constant = use all item factor\n",
    "            Yt = yi.T\n",
    "            Y = yi\n",
    "            # Confidence for user n_item x n item --> diagonalize C[user_id,:]\n",
    "            Cu = np.diag(C[user_id,:])\n",
    "            # inverse component (Y^T C^u Y + \\lambda I)\n",
    "            inv_component = np.dot(yi.T,Cu).dot(yi) + np.eye(self.n_factor)*self.lambda_reg\n",
    "            inv = np.linalg.inv(inv_component)\n",
    "\n",
    "            # non inverse component Y^T C^u p(u)\n",
    "            p_u = P[user_id,:]\n",
    "            non_inverse_component = (Yt).dot(Cu).dot(p_u)\n",
    "\n",
    "            xu_solution = inv.dot(non_inverse_component)\n",
    "\n",
    "            # update xu\n",
    "            xu[user_id,:] = xu_solution\n",
    "\n",
    "        # iterate all over item , to update item factor\n",
    "        for item_id in range(self.n_item) :\n",
    "            # holding user factor constant\n",
    "            Xt = xu.T\n",
    "            X = xu\n",
    "            # Confidence for item , <n_user x n_user> --> diagonalize C.T[item_id,:]\n",
    "            Ci = np.diag(C.T[item_id,:])\n",
    "            # inverse component (Y^T C^u Y + \\lambda I)\n",
    "            inv_component = np.dot(Xt,Ci).dot(X) + np.eye(self.n_factor)*self.lambda_reg\n",
    "            inv = np.linalg.inv(inv_component)\n",
    "\n",
    "            # non inverse component X^T C^i p(i)\n",
    "            p_i = P.T[item_id,:]\n",
    "            non_inverse_component = (Xt).dot(Ci).dot(p_i)\n",
    "\n",
    "            yi_solution = inv.dot(non_inverse_component)\n",
    "\n",
    "            # update xu\n",
    "            yi[item_id,:] =  yi_solution\n",
    "\n",
    "        return xu,yi\n",
    "\n",
    "    def plot_loss(self) :\n",
    "        \"\"\"Function to plot the loss during training\"\"\"\n",
    "        return plt.plot([x for x in range(self.n_epoch)],self.loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.51it/s]\n"
     ]
    }
   ],
   "source": [
    "als_model = AlternatingLeastSquares()\n",
    "als_model.fit(utility_data= mapped_data,user_column='userID',\n",
    "              item_column='artistID',\n",
    "              utility_column='weight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7c35f9b4eca0>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "als_model.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that because our model is not in iterative manner to find best parameter, instead we use Analytical Solution with Alternating Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let say, we want to predict the preference to user 1 on item 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996879497092995"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_target = 1\n",
    "item_target = 1\n",
    "pred = als_model.predict(userid= user_target,itemid= item_target)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compare to our original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_preference = als_model.P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we slice the the preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_preference[user_target,item_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our prediction is close enough, now we will evaluate in context of generated prediction using Precision Metrics, the way is simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For, easier calculation we will use function to measure **Precision@K**, we are going to use using Precision@5 recommended item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(true_relevant, recommended_items):\n",
    "    \"\"\"Function to measure precision from given list of recommendation\"\"\"\n",
    "    # Set a counter\n",
    "    relevant_item_count = 0\n",
    "\n",
    "    # Loop all over recommendation list\n",
    "    for item in recommended_items:\n",
    "        if item in true_relevant:\n",
    "            # If in true relevant add 1\n",
    "            relevant_item_count +=1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Divide by number of recommended_items\n",
    "    precision =  relevant_item_count / len(recommended_items)\n",
    "\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09259259259259259"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty dictionary to\n",
    "# loop all over userID\n",
    "precision_all = np.zeros(mapped_data.userID.nunique() )\n",
    "n_item_to_recommend = 5\n",
    "\n",
    "for user in mapped_data.userID.unique() :\n",
    "    user_recommendation = pd.DataFrame()\n",
    "    # loop all over artistID\n",
    "    recommended_artist = []\n",
    "    artist_score = []\n",
    "    for artist in mapped_data.artistID.unique() :\n",
    "        recommended_artist.append(artist)\n",
    "        preference_score = als_model.predict(userid=user, itemid= artist)\n",
    "        artist_score.append(preference_score)\n",
    "    user_recommendation['artist_id'] = recommended_artist\n",
    "    user_recommendation['score'] = artist_score\n",
    "    # sort the score\n",
    "    user_recommendation = user_recommendation.sort_values('score',ascending=False).head(n_item_to_recommend)\n",
    "    # pick at k highest score\n",
    "    recommendation = user_recommendation['artist_id'].values.tolist()\n",
    "    # compare to data in mapped data\n",
    "    user_true_consumed_item = mapped_data.loc[mapped_data['userID']==user,'artistID'].tolist()\n",
    "\n",
    "    # we may have item recommended > number of user consumed item\n",
    "    at_k = min(n_item_to_recommend,len(user_true_consumed_item))\n",
    "\n",
    "    precision_at_k = precision(true_relevant = user_true_consumed_item[:at_k],\n",
    "                               recommended_items = recommendation[:at_k])\n",
    "    # append precision\n",
    "    precision_all[user] = precision_at_k\n",
    "\n",
    "avg_precision_atk = np.mean(precision_all)\n",
    "avg_precision_atk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Recommender System Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train all model candidate with its hyperparameter so that we can compare which model + settings yield good result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../assets/model_training.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since *Hyperparameter* Is not yielded through learning process, we have to find it / set it to yield optimal model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some methods  Hyperparameter Tuning :    \n",
    "\n",
    "- GridSearchCV\n",
    "\n",
    "  Fitting model through all combinations of hyperparameter values and compare each fit → which combinations yield the best objective\n",
    "\n",
    "- RandomizedSearchCV\n",
    "\n",
    "  Fitting Model only through sampled hyperparameter candidates. Much more efficient than GridSearchCV\n",
    "\n",
    "- Bayesian Optimization\n",
    "\n",
    "  Using Bayesian Approach, which include sampling to find best parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation** Method\n",
    "\n",
    "We are going to find the best hyperparameter by comparing sampled parameter combination on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Method** : *Bayesian Optimization*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Candidate**\n",
    "\n",
    "1. Baseline Model\n",
    "2. Alternating Least Squares\n",
    "3. Logistic Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Model from Scratch may be benefit for us sometimes, such as getting know to the model inside out the model , however sometimes if we do it from scratch our code is not optimized both in data structure and languannge, since then for training purpose we will use package called [implicit](https://github.com/benfred/implicit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install it First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.7.2-cp39-cp39-manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from implicit) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.16 in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from implicit) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from implicit) (4.66.5)\n",
      "Requirement already satisfied: threadpoolctl in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from implicit) (3.5.0)\n",
      "Downloading implicit-0.7.2-cp39-cp39-manylinux2014_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_path = '../data/user_artist_play.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(song_play_data) :\n",
    "    \"\"\"\n",
    "    Function to preprocess data\n",
    "    Parameters\n",
    "    ----------\n",
    "    song_play_data : pandas.DataFrame\n",
    "        contain the song_play data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    song_play_data : pandas DataFrame\n",
    "        The sample of song_play data\n",
    "\n",
    "    mapping_user : dict\n",
    "        contain mappers :\n",
    "        1. user to id\n",
    "        2. id to user\n",
    "\n",
    "    mapping_item : dict\n",
    "        contain mappers :\n",
    "        1. item to id\n",
    "        2. id to item\n",
    "\n",
    "    \"\"\"\n",
    "    # copy to avoid overwriting the original dataframe\n",
    "    song_play_data = song_play_data.copy()\n",
    "    # mapping step\n",
    "    # mapping user to ordered id\n",
    "    user_to_id = {user : idx for idx,user in enumerate(song_play_data['userID'].unique())}\n",
    "    id_to_user = {idx : user for idx,user in enumerate(song_play_data['userID'].unique())}\n",
    "\n",
    "    # mapping item to ordered id\n",
    "    item_to_id = {item : idx for idx,item in enumerate(song_play_data['artistID'].unique())}\n",
    "    id_to_item = {idx : item for idx,item in enumerate(song_play_data['artistID'].unique())}\n",
    "\n",
    "    mapping_user = {'user_to_id' : user_to_id,'id_to_user' : id_to_user}\n",
    "    mapping_item = {'item_to_id' : item_to_id,'id_to_item' : id_to_item}\n",
    "\n",
    "    song_play_data['userID'] = song_play_data['userID'].map(user_to_id)\n",
    "    song_play_data['artistID'] = song_play_data['artistID'].map(item_to_id)\n",
    "\n",
    "\n",
    "    # create utility matrix\n",
    "    row = song_play_data['userID'].values\n",
    "    col = song_play_data['artistID'].values\n",
    "    data = song_play_data['weight'].values\n",
    "\n",
    "\n",
    "    utility_matrix = sp.coo_matrix((data, (row, col)))\n",
    "     # return all product(including mapping)\n",
    "    return utility_matrix, mapping_user,mapping_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape : (92834, 3)\n"
     ]
    }
   ],
   "source": [
    "song_data_full = load_song_data(path=full_data_path)\n",
    "song_utility_matrix,mapping_user,mapping_item = preprocess_data(song_play_data = song_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1892x17632 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 92834 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_utility_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to split the data into Three Subset :  \n",
    "1. Training 60%\n",
    "2. Validation 20%\n",
    "3. Testing 20%\n",
    "\n",
    "to perform this we can use `implicit.evaluation.train_test_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from implicit.evaluation import train_test_split\n",
    "\n",
    "# split data into train and test\n",
    "train_full,test = train_test_split(song_utility_matrix,train_percentage=0.8)\n",
    "\n",
    "# split from train to train and val to make val 20% from all we need to take 25% from training\n",
    "train,val = train_test_split(train_full,train_percentage=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape 55631\n",
      "val shape 18501\n",
      "test shape 18501\n"
     ]
    }
   ],
   "source": [
    "print('train shape',train.nnz)\n",
    "print('val shape',val.nnz)\n",
    "print('test shape',val.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Model Object**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Baseline Model**\n",
    "\n",
    "What baseline model do could be based on popular item list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[289, 72, 89, 292, 498]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take most listened artist\n",
    "n_popular = 5\n",
    "most_popular_artist = (song_data_full\n",
    "                       .groupby('artistID')\n",
    "                       .agg({'weight':'sum'})\n",
    "                       .sort_values('weight',ascending=False)\n",
    "                       .head(5)\n",
    "                       .reset_index()\n",
    "                       .loc[:,'artistID']).values.tolist()\n",
    "most_popular_artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring Precision @5 for Popular Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create empty dictionary to\n",
    "# loop all over userID\n",
    "precision_baseline = np.zeros(mapped_data.userID.nunique() )\n",
    "n_item_to_recommend = 5\n",
    "\n",
    "for user in mapped_data.userID.unique() :\n",
    "\n",
    "    user_true_consumed_item = mapped_data.loc[mapped_data['userID']==user,'artistID'].tolist()\n",
    "\n",
    "    # we may have item recommended > number of user consumed item\n",
    "    at_k = min(n_item_to_recommend,len(user_true_consumed_item))\n",
    "\n",
    "    precision_at_k = precision(true_relevant = user_true_consumed_item,\n",
    "                               recommended_items = most_popular_artist[:at_k])\n",
    "    # append precision\n",
    "    precision_all[user] = precision_at_k\n",
    "\n",
    "avg_precision_baseline = np.mean(precision_all)\n",
    "avg_precision_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our baseline does not give any good performance here.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be using package called implicit, the package source code is fully optimized and considered fast, we can use full data.\n",
    "\n",
    "We are going to run Hyperparameter Tuning for each model to know which model are the best , however our package, does not provide the hyperparameter tuning. Why don't we create one. We are going to create RandomizedSearchCV.\n",
    "\n",
    "So previously, we are only using sampled version of the data, because we are only demonstrating how the model works, and obviously our code is not fully optimized yet (Language and Data Structure).\n",
    "\n",
    "During model fitting process we will also use Hyperparameter Tuning to find best parameter combination to each model , for that we will use Bayesian Optimization Approach, using Optuna, we need to install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.35-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: tqdm in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from optuna) (4.66.5)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-3.1.1-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting MarkupSafe>=0.9.2 (from Mako->alembic>=1.5.0->optuna)\n",
      "  Downloading MarkupSafe-3.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
      "Downloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (597 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m597.4/597.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Downloading MarkupSafe-3.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Installing collected packages: PyYAML, MarkupSafe, greenlet, colorlog, sqlalchemy, Mako, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 MarkupSafe-3.0.1 PyYAML-6.0.2 alembic-1.13.3 colorlog-6.8.2 greenlet-3.1.1 optuna-4.0.0 sqlalchemy-2.0.35\n"
     ]
    }
   ],
   "source": [
    "# install optuna\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Alternating Least Squares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter :      \n",
    "- factors : Number of Latent Factor\n",
    "- regularization : regularization strength\n",
    "- alpha : for confidence term $c= 1 + \\alpha log(1+r_{ui})$\n",
    "\n",
    "\n",
    "Some candidate value we will use\n",
    "- factors : `[10,50,100,200,500]`\n",
    "- regularization : `[0.0001, 0.001, 0.1 , 1.0 ]`\n",
    "- alpha : `[0.001, 0.1 , 1.0,5.0 ]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to create hyperparameter tuning, according to optuna documentation, we need to create objective, our goal is to find precision / recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-09 15:39:58,134] A new study created in memory with name: no-name-b8478eb4-60a5-4efb-99e2-f29dd6b19cdf\n",
      "/home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages/optuna/distributions.py:689: UserWarning: The distribution is specified by [0.0001, 1.0] and step=0.001, but the range is not divisible by `step`. It will be replaced by [0.0001, 0.9991].\n",
      "  warnings.warn(\n",
      "/home/daniel/Documents/learning/recommendation_system/.venv/lib/python3.9/site-packages/implicit/cpu/als.py:95: RuntimeWarning: OpenBLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'OPENBLAS_NUM_THREADS=1' or by calling 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having OpenBLAS use a threadpool can lead to severe performance issues here.\n",
      "  check_blas_config()\n",
      "100%|██████████| 15/15 [00:00<00:00, 17.19it/s]\n",
      "100%|██████████| 1884/1884 [00:00<00:00, 2179.59it/s]\n",
      "[I 2024-10-09 15:39:59,943] Trial 0 finished with value: -0.11072887551064287 and parameters: {'factors': 20, 'regularization': 0.10310000000000001, 'alpha': 0.553}. Best is trial 0 with value: -0.11072887551064287.\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.05it/s]\n",
      "100%|██████████| 1884/1884 [00:00<00:00, 2823.76it/s]\n",
      "[I 2024-10-09 15:40:04,395] Trial 1 finished with value: -0.17254353902386582 and parameters: {'factors': 90, 'regularization': 0.0961, 'alpha': 0.022000000000000002}. Best is trial 1 with value: -0.17254353902386582.\n"
     ]
    }
   ],
   "source": [
    "# for evaluation\n",
    "from implicit.evaluation import precision_at_k\n",
    "\n",
    "import optuna\n",
    "\n",
    "# import model alternating least squares\n",
    "from implicit import als\n",
    "\n",
    "def als_tuning(trial):\n",
    "    factors = trial.suggest_int(name='factors',\n",
    "                                             low=10,\n",
    "                                             high=100,step=10)\n",
    "    regularization = trial.suggest_float(name='regularization',\n",
    "                                         low=0.0001,\n",
    "                                         high=1.0,\n",
    "                                         step= 0.001)\n",
    "\n",
    "    alpha = trial.suggest_float(name='alpha',\n",
    "                                      low=0.001,\n",
    "                                      high=1.0,\n",
    "                                      step= 0.001)\n",
    "\n",
    "    # instanciate model\n",
    "    model_als = als.AlternatingLeastSquares(factors=factors,\n",
    "                                            regularization= regularization,\n",
    "                                            alpha= alpha)\n",
    "\n",
    "    # fit model\n",
    "    model_als.fit(train)\n",
    "\n",
    "    # test\n",
    "    val_metrics = precision_at_k(model = model_als, train_user_items= train,\n",
    "                                  test_user_items = val,K=5)\n",
    "    return -val_metrics\n",
    "\n",
    "# minimizing is equal to\n",
    "study_als = optuna.create_study(direction=\"minimize\")\n",
    "study_als.optimize(als_tuning, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factors': 90, 'regularization': 0.0961, 'alpha': 0.022000000000000002}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check best parameters and best score\n",
    "study_als.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17254353902386582"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-study_als.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Logistic Matrix Factorization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter :      \n",
    "- factors : Number of Latent Factor\n",
    "- regularization : regularization strength\n",
    "- learning_rate  : learning rate for gradient update\n",
    "- neg_prop : number of negative samples to train when having 1 positive items\n",
    "\n",
    "Some candidate value we will use\n",
    "- factors : `10 to 500`\n",
    "- regularization : `0.0001 to  1.0 `\n",
    "- learning_rate : `0.001 to 1 `\n",
    "- neg_prop : `10 to 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-09 15:40:30,338] A new study created in memory with name: no-name-642b75f5-9af2-45ac-879b-d793266f1b7f\n",
      "100%|██████████| 30/30 [00:00<00:00, 66.17it/s]\n",
      "100%|██████████| 1884/1884 [00:00<00:00, 2607.69it/s]\n",
      "[I 2024-10-09 15:40:31,534] Trial 0 finished with value: -0.0074177596215867555 and parameters: {'factor': 10, 'neg_prop': 80, 'regularization': 0.3061, 'learning_rate': 0.8230000000000001}. Best is trial 0 with value: -0.0074177596215867555.\n",
      "100%|██████████| 30/30 [00:02<00:00, 10.86it/s]\n",
      "100%|██████████| 1884/1884 [00:00<00:00, 2295.59it/s]\n",
      "[I 2024-10-09 15:40:35,220] Trial 1 finished with value: -0.004192646742635992 and parameters: {'factor': 90, 'neg_prop': 50, 'regularization': 0.29009999999999997, 'learning_rate': 0.28600000000000003}. Best is trial 0 with value: -0.0074177596215867555.\n"
     ]
    }
   ],
   "source": [
    "# import model logistic matrix factorization\n",
    "from implicit import lmf\n",
    "\n",
    "def lmf_tuning(trial):\n",
    "    factors = trial.suggest_int(name='factor',\n",
    "                                             low=10,\n",
    "                                             high=100,step=10)\n",
    "    neg_prop = trial.suggest_int(name='neg_prop',\n",
    "                                             low=10,\n",
    "                                             high=100,step=10)\n",
    "\n",
    "    regularization = trial.suggest_float(name='regularization',\n",
    "                                         low=0.0001,\n",
    "                                         high=1.0,\n",
    "                                         step= 0.001)\n",
    "\n",
    "    learning_rate = trial.suggest_float(name='learning_rate',\n",
    "                                      low=0.001,\n",
    "                                      high=1.0,\n",
    "                                      step= 0.001)\n",
    "\n",
    "    # instanciate model\n",
    "    model_lmf = lmf.LogisticMatrixFactorization(factors=factors,\n",
    "                                            regularization= regularization,\n",
    "                                            learning_rate= learning_rate,\n",
    "                                            neg_prop = neg_prop)\n",
    "\n",
    "    # fit model\n",
    "    model_lmf.fit(train)\n",
    "\n",
    "    # test\n",
    "    val_metrics = precision_at_k(model = model_lmf, train_user_items= train,\n",
    "                                  test_user_items = val,K=5)\n",
    "    return -val_metrics\n",
    "\n",
    "# minimizing is equal to\n",
    "study_lmf = optuna.create_study(direction=\"minimize\")\n",
    "study_lmf.optimize(lmf_tuning, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'factor': 10,\n",
       " 'neg_prop': 80,\n",
       " 'regularization': 0.3061,\n",
       " 'learning_rate': 0.8230000000000001}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_lmf.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0074177596215867555"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*study_lmf.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After, we run experiment to our model, its better to recap the performance of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Performance - Precision @5</th>\n",
       "      <th>Model Condiguration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alternating Least Squares</td>\n",
       "      <td>0.172544</td>\n",
       "      <td>{'factors': 90, 'regularization': 0.0961, 'alp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Matrix Factorization</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>{'factor': 10, 'neg_prop': 80, 'regularization...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  CV Performance - Precision @5  \\\n",
       "0                       Baseline                       0.000000   \n",
       "1      Alternating Least Squares                       0.172544   \n",
       "2  Logistic Matrix Factorization                       0.007418   \n",
       "\n",
       "                                 Model Condiguration  \n",
       "0                                                N/A  \n",
       "1  {'factors': 90, 'regularization': 0.0961, 'alp...  \n",
       "2  {'factor': 10, 'neg_prop': 80, 'regularization...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame({'Model': ['Baseline', 'Alternating Least Squares','Logistic Matrix Factorization'],\n",
    "                           'CV Performance - Precision @5': [avg_precision_baseline,-1*study_als.best_value,-1*study_lmf.best_value],\n",
    "                           'Model Condiguration':['N/A',f'{study_als.best_params}',\n",
    "                                                  f'{study_lmf.best_params}']})\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have alternating Least Squares as our Best Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Best Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will train, our best models, **Alternating Least Squares** on full training data (Train + Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:03<00:00,  3.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create object\n",
    "best_params_als = study_als.best_params\n",
    "model_best = als.AlternatingLeastSquares(**best_params_als)\n",
    "\n",
    "# Retrain on whole train dataset\n",
    "model_best.fit(train_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Best Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Decision Support Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the best model, we can sanity check the performance on the test dataset.\n",
    "Next, we predict the test set using our best model, using **Preccision @5**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1878/1878 [00:00<00:00, 2486.04it/s]\n"
     ]
    }
   ],
   "source": [
    "test_score = precision_at_k(model = model_best, train_user_items= train_full,\n",
    "                                  test_user_items = test,K=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision@5-Tuning</th>\n",
       "      <th>Precision@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alternating Least Squares</td>\n",
       "      <td>0.172544</td>\n",
       "      <td>0.250484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Precision@5-Tuning  Precision@5\n",
       "0  Alternating Least Squares            0.172544     0.250484"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_test_df = pd.DataFrame({'Model' : ['Alternating Least Squares'],\n",
    "                                'Precision@5-Tuning': [-study_als.best_value],\n",
    "                                'Precision@5': [test_score]})\n",
    "\n",
    "summary_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Process is to recommend items to user\n",
    "from our trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.Predictions / Generating Recommendation**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we generate recommendation ?\n",
    "\n",
    "\n",
    "To generate recommendation :\n",
    "- predict all movies or only unseen movies rating from given users\n",
    "- followed by ordering the movies by its predicted rat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method recommend in module implicit.cpu.matrix_factorization_base:\n",
      "\n",
      "recommend(userid, user_items, N=10, filter_already_liked_items=True, filter_items=None, recalculate_user=False, items=None) method of implicit.cpu.als.AlternatingLeastSquares instance\n",
      "    Recommends items for users.\n",
      "    \n",
      "    This method allows you to calculate the top N recommendations for a user or\n",
      "    batch of users. Passing an array of userids instead of a single userid will\n",
      "    tend to be more efficient, and allows multi-thread processing on the CPU.\n",
      "    \n",
      "    This method has options for filtering out items from the results. You can both\n",
      "    filter out items that have already been liked by the user with the\n",
      "    filter_already_liked_items parameter, as well as pass in filter_items to filter\n",
      "    out other items for all users in the batch. By default all items in the training\n",
      "    dataset are scored, but by setting the 'items' parameter you can restrict down to\n",
      "    a subset.\n",
      "    \n",
      "    Example usage::\n",
      "    \n",
      "        # calculate the top recommendations for a single user\n",
      "        ids, scores = model.recommend(0, user_items[0])\n",
      "    \n",
      "        # calculate the top recommendations for a batch of users\n",
      "        userids = np.arange(10)\n",
      "        ids, scores = model.recommend(userids, user_items[userids])\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    userid : Union[int, array_like]\n",
      "        The userid or array of userids to calculate recommendations for\n",
      "    user_items : csr_matrix\n",
      "        A sparse matrix of shape (users, number_items). This lets us look\n",
      "        up the liked items and their weights for the user. This is used to filter out\n",
      "        items that have already been liked from the output, and to also potentially\n",
      "        recalculate the user representation. Each row in this sparse matrix corresponds\n",
      "        to a row in the userid parameter: that is the first row in this matrix contains\n",
      "        the liked items for the first user in the userid array.\n",
      "    N : int, optional\n",
      "        The number of results to return\n",
      "    filter_already_liked_items: bool, optional\n",
      "        When true, don't return items present in the training set that were rated\n",
      "        by the specified user.\n",
      "    filter_items : array_like, optional\n",
      "        List of extra item ids to filter out from the output\n",
      "    recalculate_user : bool, optional\n",
      "        When true, don't rely on stored user embeddings and instead recalculate from the\n",
      "        passed in user_items. This option isn't supported by all models.\n",
      "    items: array_like, optional\n",
      "        Array of extra item ids. When set this will only rank the items in this array instead\n",
      "        of ranking every item the model was fit for. This parameter cannot be used with\n",
      "        filter_items\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    tuple\n",
      "        Tuple of (itemids, scores) arrays. When calculating for a single user these array will\n",
      "        be 1-dimensional with N items. When passed an array of userids, these will be\n",
      "        2-dimensional arrays with a row for each user.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recommendation based on Best Models\n",
    "# We will try to recommend on sample userid ,userId 1 & 99\n",
    "\n",
    "# We can use model_best.recommend\n",
    "help(model_best.recommend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model_best.recommend` has argument\n",
    "- `userid` : userID\n",
    "- `user_items` : Utility matrix for trianing model\n",
    "- `N=10` : Number of item to recommend\n",
    "- `filter_already_liked_items` : Whether to recommend seen items or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Recommend artist to User 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[282, 206,  16, 110, 253, 176, 418, 276, 244, 494]], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = [9]\n",
    "\n",
    "recommended_artist_id,_ = model_best.recommend(userid= user_id, user_items= train_full[user_id], N=10 )\n",
    "recommended_artist_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>userID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>282</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>253</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>176</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>418</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>276</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>244</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>494</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistID  userID\n",
       "0       282       9\n",
       "1       206       9\n",
       "2        16       9\n",
       "3       110       9\n",
       "4       253       9\n",
       "5       176       9\n",
       "6       418       9\n",
       "7       276       9\n",
       "8       244       9\n",
       "9       494       9"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe first\n",
    "recommended_artist_df = pd.DataFrame()\n",
    "recommended_artist_df['artistID'] = recommended_artist_id[0]\n",
    "recommended_artist_df['userID'] = 9\n",
    "recommended_artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have the recommended artist, however we don't have idea who it is, so we can load artist metadata to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to map back the `artistID` to original id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item_to_id', 'id_to_item'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_item.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>userID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>257</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>227</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>468</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>327</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>295</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>544</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistID  userID\n",
       "0       333       9\n",
       "1       257       9\n",
       "2        67       9\n",
       "3       161       9\n",
       "4       304       9\n",
       "5       227       9\n",
       "6       468       9\n",
       "7       327       9\n",
       "8       295       9\n",
       "9       544       9"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_artist_df['artistID'] = recommended_artist_df['artistID'].map(mapping_item['id_to_item'])\n",
    "recommended_artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the artist metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>pictureURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MALICE MIZER</td>\n",
       "      <td>http://www.last.fm/music/MALICE+MIZER</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/10808.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Diary of Dreams</td>\n",
       "      <td>http://www.last.fm/music/Diary+of+Dreams</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/3052066.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Carpathian Forest</td>\n",
       "      <td>http://www.last.fm/music/Carpathian+Forest</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/40222717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Moi dix Mois</td>\n",
       "      <td>http://www.last.fm/music/Moi+dix+Mois</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/54697835...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bella Morte</td>\n",
       "      <td>http://www.last.fm/music/Bella+Morte</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/14789013...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               name                                         url  \\\n",
       "0   1       MALICE MIZER       http://www.last.fm/music/MALICE+MIZER   \n",
       "1   2    Diary of Dreams    http://www.last.fm/music/Diary+of+Dreams   \n",
       "2   3  Carpathian Forest  http://www.last.fm/music/Carpathian+Forest   \n",
       "3   4       Moi dix Mois       http://www.last.fm/music/Moi+dix+Mois   \n",
       "4   5        Bella Morte        http://www.last.fm/music/Bella+Morte   \n",
       "\n",
       "                                          pictureURL  \n",
       "0    http://userserve-ak.last.fm/serve/252/10808.jpg  \n",
       "1  http://userserve-ak.last.fm/serve/252/3052066.jpg  \n",
       "2  http://userserve-ak.last.fm/serve/252/40222717...  \n",
       "3  http://userserve-ak.last.fm/serve/252/54697835...  \n",
       "4  http://userserve-ak.last.fm/serve/252/14789013...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_metadata_path = '../data/artist_name.csv'\n",
    "\n",
    "# read dataframe\n",
    "artist_name = pd.read_csv(artist_metadata_path)\n",
    "artist_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>userID</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333</td>\n",
       "      <td>9</td>\n",
       "      <td>Avril Lavigne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>257</td>\n",
       "      <td>9</td>\n",
       "      <td>Mariah Carey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>Madonna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161</td>\n",
       "      <td>9</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>9</td>\n",
       "      <td>David Archuleta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>227</td>\n",
       "      <td>9</td>\n",
       "      <td>The Beatles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>468</td>\n",
       "      <td>9</td>\n",
       "      <td>Usher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>327</td>\n",
       "      <td>9</td>\n",
       "      <td>Chris Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>295</td>\n",
       "      <td>9</td>\n",
       "      <td>Beyoncé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>544</td>\n",
       "      <td>9</td>\n",
       "      <td>Adam Lambert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistID  userID       artist_name\n",
       "0       333       9     Avril Lavigne\n",
       "1       257       9      Mariah Carey\n",
       "2        67       9           Madonna\n",
       "3       161       9  Enrique Iglesias\n",
       "4       304       9   David Archuleta\n",
       "5       227       9       The Beatles\n",
       "6       468       9             Usher\n",
       "7       327       9       Chris Brown\n",
       "8       295       9           Beyoncé\n",
       "9       544       9      Adam Lambert"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge data\n",
    "recommended_artist_df['artist_name'] = recommended_artist_df.merge(artist_name,right_on='id',left_on='artistID').loc[:,'name']\n",
    "\n",
    "recommended_artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create a function to create recommendation for all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_to_users(userid,user_items=train_full,N=10, artist_name = artist_name,\n",
    "                       mapping_item = mapping_item) :\n",
    "    # collect user id\n",
    "    user_id = [userid]\n",
    "    #\n",
    "    recommended_artist_id,_ = model_best.recommend(userid= user_id, user_items= train_full[user_id], N=N )\n",
    "\n",
    "    # create dataframe first\n",
    "    recommended_artist_df = pd.DataFrame()\n",
    "    recommended_artist_df['artistID'] = recommended_artist_id[0]\n",
    "    recommended_artist_df['userID'] = userid\n",
    "\n",
    "\n",
    "    recommended_artist_df['artistID'] = recommended_artist_df['artistID'].map(mapping_item['id_to_item'])\n",
    "    # merge data\n",
    "    recommended_artist_df['artist_name'] = recommended_artist_df.merge(artist_name,\n",
    "                                                                       right_on='id',left_on='artistID').loc[:,'name']\n",
    "    return recommended_artist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to recommend to user 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>userID</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>748</td>\n",
       "      <td>100</td>\n",
       "      <td>Boards of Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1745</td>\n",
       "      <td>100</td>\n",
       "      <td>Apparat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1965</td>\n",
       "      <td>100</td>\n",
       "      <td>Four Tet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2605</td>\n",
       "      <td>100</td>\n",
       "      <td>Bonobo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1098</td>\n",
       "      <td>100</td>\n",
       "      <td>Björk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2691</td>\n",
       "      <td>100</td>\n",
       "      <td>Telefon Tel Aviv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1943</td>\n",
       "      <td>100</td>\n",
       "      <td>Flying Lotus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4865</td>\n",
       "      <td>100</td>\n",
       "      <td>ISAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7493</td>\n",
       "      <td>100</td>\n",
       "      <td>Luke Vibert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>767</td>\n",
       "      <td>100</td>\n",
       "      <td>Gridlock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistID  userID       artist_name\n",
       "0       748     100  Boards of Canada\n",
       "1      1745     100           Apparat\n",
       "2      1965     100          Four Tet\n",
       "3      2605     100            Bonobo\n",
       "4      1098     100             Björk\n",
       "5      2691     100  Telefon Tel Aviv\n",
       "6      1943     100      Flying Lotus\n",
       "7      4865     100              ISAN\n",
       "8      7493     100       Luke Vibert\n",
       "9       767     100          Gridlock"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommendation to user 100\n",
    "recommend_to_users(userid=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>userID</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>1000</td>\n",
       "      <td>Coldplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>374</td>\n",
       "      <td>1000</td>\n",
       "      <td>宇多田ヒカル</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378</td>\n",
       "      <td>1000</td>\n",
       "      <td>Evanescence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>913</td>\n",
       "      <td>1000</td>\n",
       "      <td>Destiny's Child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349</td>\n",
       "      <td>1000</td>\n",
       "      <td>The Pussycat Dolls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>288</td>\n",
       "      <td>1000</td>\n",
       "      <td>Rihanna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>289</td>\n",
       "      <td>1000</td>\n",
       "      <td>Britney Spears</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>548</td>\n",
       "      <td>1000</td>\n",
       "      <td>Ellie Goulding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>251</td>\n",
       "      <td>1000</td>\n",
       "      <td>Whitney Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2094</td>\n",
       "      <td>1000</td>\n",
       "      <td>BoA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistID  userID         artist_name\n",
       "0        65    1000            Coldplay\n",
       "1       374    1000              宇多田ヒカル\n",
       "2       378    1000         Evanescence\n",
       "3       913    1000     Destiny's Child\n",
       "4       349    1000  The Pussycat Dolls\n",
       "5       288    1000             Rihanna\n",
       "6       289    1000      Britney Spears\n",
       "7       548    1000      Ellie Goulding\n",
       "8       251    1000     Whitney Houston\n",
       "9      2094    1000                 BoA"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommendation to user 1000\n",
    "recommend_to_users(userid=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
