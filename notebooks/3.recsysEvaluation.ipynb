{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cO5oLZWWEaB"
   },
   "source": [
    "# **3. Evaluating Recommender System**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAYgWFXeDm2o"
   },
   "source": [
    "---\n",
    "## Outline:\n",
    "\n",
    "1. Evaluation  : Intro\n",
    "2. Prediction Accuracy Metrics\n",
    "3. Decision Support  Metrics\n",
    "4. Rank Aware Top N Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie4mHq7Yccoy"
   },
   "source": [
    "## 1. Evaluation : Intro\n",
    "\n",
    "1. Offline Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoTzq7gGTk9s"
   },
   "source": [
    "## 2. Prediction Accuracy Metrics\n",
    "\n",
    "1. Mean Absolute Error\n",
    "2. Mean Squared Error\n",
    "3. Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVd-hGcCTD1f"
   },
   "source": [
    "## 3. Decision Support Metrics\n",
    "\n",
    "1. Precision\n",
    "2. Recall\n",
    "3. Balancing Precision + Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqmDuT4ufLrS"
   },
   "source": [
    "## 4.Rank Aware Top N Metrics\n",
    "\n",
    "1. Mean Average Precision\n",
    "2. Discounted Cumulative Gain\n",
    "3. Normalized Discounted Cumulative Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUl2Q9jlSLBg"
   },
   "source": [
    "# **1.Evaluation : Intro**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osqWGVDyUERB"
   },
   "source": [
    "Some approach we can use in recommender system problems:     \n",
    "- Predict Utility of each Item to each User\n",
    "- Classify each item relevancy to each User\n",
    "- Ranking Each Item Based on user preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7lOO35LVTeo"
   },
   "source": [
    "After choosing right approach we will move into modelling phase, we need to **evaluate** our model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PB8IQHlVly6"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/recsys_evaluation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGuTDJOFWfGa"
   },
   "source": [
    "For now, we will focus on **Offline Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd_b4rsqXAnp"
   },
   "source": [
    "### **Offline Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IECuoBVXGKg"
   },
   "source": [
    "Offline Evaluation **focuses** on evaluating model performances, we want :      \n",
    "- Not Only Good in Training\n",
    "- Have robust performance in future (unseen) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CylvljljYcgz"
   },
   "source": [
    "Since we have variety approach in modelling recommender system problem , hence we have variety measure on evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMRhKxeUayAp"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/recsys_evaluation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UbxpDTqMjwD"
   },
   "source": [
    "# **2. Prediction Accuracy Metrics**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sFY159MLpWx"
   },
   "source": [
    "What do we do?\n",
    "1. Recommender System with Rating Prediction Approach\n",
    "2. Variety of Metrics\n",
    "3. Choosing Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxpX-m6jL41l"
   },
   "source": [
    "## 2.1. Recommender System with Rating Prediction Approach.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mns5Oiz3R9K1"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/users_matrix.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCLTXI2AMpeF"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/recsys_trainig_flow.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcksUXJSPjGF"
   },
   "source": [
    "In this approach the utility **considered** as number how much continous value that express how like user to an item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DluyseRbeUO9"
   },
   "source": [
    "example  :\n",
    "- movie rating\n",
    "- e-commerce rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv2fbqw1e2um"
   },
   "source": [
    "Based on those, we can conclude that our model considered as **good model** when the prediction is close to its truth as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Fix5t0-fboS"
   },
   "source": [
    "Since we are predicting the rating the utility value (such as rating), we considered this as a **regression task** , some metrics suitable are :      \n",
    "- Mean Absolute Error\n",
    "- Mean Squared Error\n",
    "- Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceiI0VP_iFqj"
   },
   "source": [
    "Example : We have are training movie recommender system , the model goal is to predict item rating that will be given from certain user  and recommend item that have highest predictred ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuMfRscsi0MI"
   },
   "source": [
    "We final check the model on test set to measure its performance, we trained 2 models for benchmarking purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZfYT8tGlsTa"
   },
   "source": [
    "Model A predict item B rating **3.8** , while model B predict **4.5**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocFXB7p2i7xS"
   },
   "source": [
    "\n",
    "We will take userA prediction on item B\n",
    "Which has true rating (4.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZeqImB4m31o"
   },
   "outputs": [],
   "source": [
    "# The true ratings user a on item b\n",
    "true_ratings_b = 4.2\n",
    "\n",
    "# The predicted rating from RecSys models\n",
    "predicted_ratings_modelA = 3.9\n",
    "predicted_ratings_modelB = 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGYwGmlAd7v2"
   },
   "source": [
    "## 2.2. Variety of Metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gC_lBHu_hpQs"
   },
   "source": [
    "### 1. Mean Absolute Error (MAE)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YT8TPZN7hx4o"
   },
   "source": [
    "One way to measure prediction accuracy is measure the prediction error as\n",
    "\n",
    "$$\n",
    "\\text{Error} = (\\text{True Rating} - \\text{Predicted Ratings})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAYFVBynmdWo",
    "outputId": "2bc26f15-1e7a-48b7-ce6e-ab8b154c0dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error model A: 0.30000000000000027\n"
     ]
    }
   ],
   "source": [
    "# Error from model A\n",
    "error_a = true_ratings_b - predicted_ratings_modelA\n",
    "\n",
    "# Print\n",
    "print('Error model A:', error_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ZjvqUcVmxTs",
    "outputId": "f5be9edf-acc7-4dd6-d79f-e6fe7785cfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error model B: -0.2999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Error from model B\n",
    "error_b = true_ratings_b - predicted_ratings_modelB\n",
    "\n",
    "# Print\n",
    "print('Error model B:', error_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxknE4penm8C"
   },
   "source": [
    "**What we observe?**\n",
    "- There are negative & positive errors\n",
    "- The difference between the true rating and predicted ratings should be 0.3\n",
    "\n",
    "**Is there a problem?**\n",
    "- Yes, the sum of error of several predictions can be 0 (no error).\n",
    "- This could be misleading.\n",
    "\n",
    "**Solution?**\n",
    "- Let's take an absolute value of this error\n",
    "- And that's how it called by *absolute error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7-dcodWiEyG",
    "outputId": "f924932a-4a44-4dfb-e70b-360957440ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error model A: 0.30000000000000027\n"
     ]
    }
   ],
   "source": [
    "# Absolute error from model A\n",
    "error_a = abs(true_ratings_b - predicted_ratings_modelA)\n",
    "\n",
    "# Print\n",
    "print('Error model A:', error_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuMPwvuAoSAS",
    "outputId": "c920f94b-1241-416e-c321-3ed8abdb35d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error model B: 0.2999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Absolute error from model B\n",
    "error_b = abs(true_ratings_b - predicted_ratings_modelB)\n",
    "\n",
    "# Print\n",
    "print('Error model B:', error_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjWVlP3MoYtk"
   },
   "source": [
    "Now our model yield the consistent & positive measurement. Again, this is called as **Absolute Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BC6j90nFoih7"
   },
   "source": [
    "$$\n",
    "\\text{Abolute Error} = |\\text{True Value} - \\text{Predicted Value}|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxP7O2ybovOD"
   },
   "source": [
    "Wait a sec, we see that measure only for one prediction, what if we want to measure all prediction, we can measure the mean of absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmjUNR3RpiGj"
   },
   "source": [
    "$$\n",
    "\\text{Mean Abolute Error}\n",
    "=\n",
    "\\cfrac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "    \\left |\n",
    "    \\text{True Value}_{i} - \\text{Predicted Value}_{i}\n",
    "    \\right|\n",
    "$$\n",
    "\n",
    "with\n",
    "$$N = \\text{number of observation}$$\n",
    "\n",
    "Now, its time to wrap into function for easier usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJadwSkbp4zn"
   },
   "source": [
    "we load the library first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0didRfIslZN"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wg2iRmLXoXsJ"
   },
   "outputs": [],
   "source": [
    "def mean_absolute_error(true_value, predicted_value) :\n",
    "    \"\"\"Function to measure mean absolute error of given prediction list\"\"\"\n",
    "    # Check if length is the same\n",
    "    assert len(true_value) == len(predicted_value)\n",
    "\n",
    "    # Convert into a Numpy Array\n",
    "    true_value = np.array(true_value)\n",
    "    predicted_value = np.array(predicted_value)\n",
    "\n",
    "    # Calculate mean of absolute error\n",
    "    mae = np.mean(np.abs(true_value-predicted_value))\n",
    "\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLh0sKWsrz0K"
   },
   "source": [
    "Now, Lets Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RT1oImwDhbT_"
   },
   "outputs": [],
   "source": [
    "# The true ratings\n",
    "true_ratings = [4.2, 4.3, 2.9, 1.3]\n",
    "\n",
    "# The predicted ratings\n",
    "model_A_pred = [4.5, 4.0, 3.3, 2.1]\n",
    "model_B_pred = [3.9, 4.3, 2.7, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XzEYDgDhqtl",
    "outputId": "7a61237e-4a19-4e4d-e523-ec2e5bd69ec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE model A: 0.4499999999999999\n",
      "MAE model B: 0.14999999999999997\n"
     ]
    }
   ],
   "source": [
    "# Calculate mae\n",
    "mae_A = mean_absolute_error(true_value = true_ratings,\n",
    "                            predicted_value = model_A_pred)\n",
    "\n",
    "mae_B = mean_absolute_error(true_value = true_ratings,\n",
    "                            predicted_value = model_B_pred)\n",
    "\n",
    "# Print\n",
    "print('MAE model A:', mae_A)\n",
    "print('MAE model B:', mae_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTYqa9sxh-P8"
   },
   "source": [
    "Which model is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9RLlMPrhrkk"
   },
   "source": [
    "### 2. Mean Squared Error (MSE)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpq1nVD8titr"
   },
   "source": [
    "Previously we try to add **absolute term** to make our error positive, is there another way to do so?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHaiGTDwt8Kq"
   },
   "source": [
    "The key is making the margin strictly positive, another way :      \n",
    "- Add square to our error measurement\n",
    "\n",
    "This called as **Squared Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "956x_Js5uXhw"
   },
   "outputs": [],
   "source": [
    "# Calculate the squared error\n",
    "# The error\n",
    "error_a = true_ratings_b - predicted_ratings_modelA\n",
    "error_b = true_ratings_b - predicted_ratings_modelB\n",
    "\n",
    "# The squared error\n",
    "squared_error_a = error_a**2\n",
    "squared_error_b = error_b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOn36vbrvm_E",
    "outputId": "6d64c874-8bfd-4273-8f84-d9688b66c94b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared Error on Model A: 0.09000000000000016\n",
      "Squared Error on Model B: 0.0899999999999999\n"
     ]
    }
   ],
   "source": [
    "print('Squared Error on Model A:', squared_error_a)\n",
    "print('Squared Error on Model B:', squared_error_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bk4IctkcwDJs"
   },
   "source": [
    "- We can see that both yield the same result.\n",
    "- We can use this as metrics.\n",
    "- Since we care about measuring Squared Error on overall prediction we can add **average term**\n",
    "\n",
    "$$\n",
    "\\text{Mean Squared Error}\n",
    "=\n",
    "\\cfrac{1}{N}\n",
    "\\sum_{i=1}^{N}\n",
    "    \\left ( \\text{True Value}_{i} - \\text{Predicted Value}_{i}\n",
    "    \\right)^{2}\n",
    "$$\n",
    "\n",
    "with\n",
    "$$N = \\text{number of observation}$$\n",
    "\n",
    "Now, its time to wrap into function for easier usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2QoS5pMwkrh"
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(true_value, predicted_value):\n",
    "    \"\"\"Function to measure mean squared error of given prediction list\"\"\"\n",
    "    # check if length is the same\n",
    "    assert len(true_value) == len(predicted_value)\n",
    "\n",
    "    # converting list as array\n",
    "    true_value = np.array(true_value)\n",
    "    predicted_value = np.array(predicted_value)\n",
    "\n",
    "    #measure mean squared error\n",
    "    mse = np.mean((true_value-predicted_value)**2)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUcHY-nBxDLp"
   },
   "source": [
    "Its time to validate again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkgYNDv2jI_m"
   },
   "outputs": [],
   "source": [
    "# The true ratings\n",
    "true_ratings = [4.2, 4.3, 2.9, 1.3]\n",
    "\n",
    "# The predicted ratings\n",
    "model_A_pred = [4.5, 4.0, 3.3, 2.1]\n",
    "model_B_pred = [3.9, 4.3, 2.7, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fY6-fgC5xZXR",
    "outputId": "ff198f9b-035e-4663-f137-0f1d849214d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE model A: 0.24499999999999997\n",
      "MSE model B: 0.03500000000000001\n"
     ]
    }
   ],
   "source": [
    "# Calculate mse\n",
    "mse_A = mean_squared_error(true_value = true_ratings,\n",
    "                           predicted_value = model_A_pred)\n",
    "\n",
    "mse_B = mean_squared_error(true_value = true_ratings,\n",
    "                           predicted_value = model_B_pred)\n",
    "\n",
    "# Print\n",
    "print('MSE model A:', mse_A)\n",
    "print('MSE model B:', mse_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvVHjgKLx9rx"
   },
   "source": [
    "**On a side note**:\n",
    "- We see that **squaring** the difference making our measurement has different unit, not in **$\\text{rating}$** value but in **$\\text{rating}^2$**\n",
    "- It's hard to interpret something like \"our model has error of 0.25 $\\text{rating}^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKeJ8X4KyUdr"
   },
   "source": [
    "To address this problem, is there any solution ? yes ,\n",
    "- Take the root of the squared-error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9wihLpzht1-"
   },
   "source": [
    "### 3. Root Mean Squared Error (RMSE)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKcwG3SmkGjQ"
   },
   "source": [
    "As it is say, you take a square root of a squared-error, i.e. on average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOYNS5sKkTpu"
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Root Mean Squared Error}\n",
    "&= \\sqrt{\\text{Mean Squared Error}} \\\\\n",
    "\\text{RMSE}\n",
    "&= \\sqrt{\n",
    "    \\cfrac{1}{N}\n",
    "    \\sum_{i=1}^{N}\n",
    "    \\left (\n",
    "        \\text{True Value}_{i} - \\text{Predicted Value}_{i}\n",
    "    \\right )^{2}\n",
    "}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "with\n",
    "$$N = \\text{number of observation}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nt5xf-5Oz5wa"
   },
   "source": [
    "for easier usage, we will create function to measure RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isaLaWSyPWmr"
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(true_value, predicted_value) :\n",
    "    \"\"\"Function to measure mean squared error of given prediction list\"\"\"\n",
    "    # Defense\n",
    "    assert len(true_value) == len(predicted_value)\n",
    "\n",
    "    # Call mse function\n",
    "    mse = mean_squared_error(true_value=true_value,\n",
    "                             predicted_value=predicted_value)\n",
    "\n",
    "    # Divide by number of observation\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8T0DjlF0NEn"
   },
   "source": [
    "Now, its time to validate, making sure our rmse function working properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibKiBTr_3Xtb"
   },
   "source": [
    "We consider valid if/s :   \n",
    "- Both Model A and B Error is the same\n",
    "- $\\sqrt{MSE}  = RMSE $ from both model error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUCD17KHlDq_"
   },
   "outputs": [],
   "source": [
    "# The true ratings\n",
    "true_ratings = [4.2, 4.3, 2.9, 1.3]\n",
    "\n",
    "# The predicted ratings\n",
    "model_A_pred = [4.5, 4.0, 3.3, 2.1]\n",
    "model_B_pred = [3.9, 4.3, 2.7, 1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vmw-FN0J0Rr1",
    "outputId": "de544c5e-6a68-445b-887f-0cf1f8d933f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE model A: 0.49497474683058323\n",
      "RMSE model B: 0.18708286933869708\n"
     ]
    }
   ],
   "source": [
    "# Calculate rmse\n",
    "rmse_A = root_mean_squared_error(true_value = true_ratings,\n",
    "                                 predicted_value = model_A_pred)\n",
    "\n",
    "rmse_B = root_mean_squared_error(true_value = true_ratings,\n",
    "                                 predicted_value = model_B_pred)\n",
    "\n",
    "# Print\n",
    "print('RMSE model A:', rmse_A)\n",
    "print('RMSE model B:', rmse_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fonpoi8vlSx5"
   },
   "source": [
    "Does RMSE is a squared-root of MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTmsc59WlWbn",
    "outputId": "94ab058e-875f-4bb8-9a1f-033e7188f5fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_A == np.sqrt(mse_A), rmse_B == np.sqrt(mse_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bXZPaUe4Gml"
   },
   "source": [
    "From those tests we can see that our metrics / error function working properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjOd_7sl4M7P"
   },
   "source": [
    "After learning three types of metrics from **Prediction Accuracy Approach**, the question/s are :    \n",
    "- Which Metrics to Choose ?\n",
    "- Which Metrics is the best\n",
    "\n",
    "Well, to find those we have to **experiment** on our own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVVUsYN44xBr"
   },
   "source": [
    "## 2.3. Choosing Metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MO05pRJw459U"
   },
   "source": [
    "<center>\n",
    "<img src=\"https://i.imgflip.com/7t5v7a.jpg\" title=\"made at imgflip.com\"/>\n",
    "\n",
    "<br>\n",
    "<a href=\"https://imgflip.com/i/7t5v7a\">img src</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhVdWPoZ6VPc"
   },
   "source": [
    "Yes, finding correct metrics is quite tricky, one way for easier choosing metrics we will experiment one on one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DX3SIpR6yJw"
   },
   "source": [
    "### **Experiment Setup**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SPc5xkroB9_"
   },
   "source": [
    "For This experiment to illustrate way to choose right metrics ,we assume :    \n",
    "- We only trained 1 models (Model A)\n",
    "- We will compare prediction error  with high difference and low difference\n",
    "- The error will be measured on 5 item prediction on user A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R86jaUsc8QX8"
   },
   "source": [
    "### **High Margin of Errors**\n",
    "---\n",
    "\n",
    "Assumed these are the true ratings & predictions results\n",
    "\n",
    "| Model A Prediction | True Ratings |\n",
    "|-------------------:|-------------:|\n",
    "| 5                  | 1            |\n",
    "| 1                  | 5            |\n",
    "| 4                  | 2            |\n",
    "| 1                  | 5            |\n",
    "| 2                  | 5            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDhHx5RA8zL_"
   },
   "outputs": [],
   "source": [
    "# Create the data\n",
    "true_ratings = [1, 5, 4, 5, 5]\n",
    "model_A_pred = [5, 1, 4, 1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsyurAGC7XjT"
   },
   "source": [
    "**Measure Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZMpZx7eE3Xg"
   },
   "outputs": [],
   "source": [
    "mae_high = mean_absolute_error(true_value = true_ratings,\n",
    "                               predicted_value = model_A_pred)\n",
    "\n",
    "mse_high = mean_squared_error(true_value = true_ratings,\n",
    "                              predicted_value = model_A_pred)\n",
    "\n",
    "rmse_high = root_mean_squared_error(true_value = true_ratings,\n",
    "                                    predicted_value = model_A_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnd9sIYUnjju",
    "outputId": "088bcb10-7300-49fe-b367-2d4f74056718"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-d6a574bc-bc0b-4517-a263-1e69ef0b37eb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High margin of errors</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>3.376389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6a574bc-bc0b-4517-a263-1e69ef0b37eb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-f2839bdf-ca19-447c-817d-48c1da160105\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2839bdf-ca19-447c-817d-48c1da160105')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-f2839bdf-ca19-447c-817d-48c1da160105 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d6a574bc-bc0b-4517-a263-1e69ef0b37eb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d6a574bc-bc0b-4517-a263-1e69ef0b37eb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                    case  MAE   MSE      RMSE\n",
       "0  High margin of errors  3.0  11.4  3.376389"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create summary\n",
    "import pandas as pd\n",
    "\n",
    "summary_high = pd.DataFrame({'case': ['High margin of errors'],\n",
    "                             'MAE': [mae_high],\n",
    "                             'MSE': [mse_high],\n",
    "                             'RMSE': [rmse_high]})\n",
    "\n",
    "summary_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKAXLcKAHBsQ"
   },
   "source": [
    "We can see that the result shows :  \n",
    "- Squared Error based metrics (RMSE + MSE) yield higher error due to suared operation\n",
    "\n",
    "- MAE yield lower error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srF7JKDDFAux"
   },
   "source": [
    "### **Low Margin of Error**\n",
    "---\n",
    "\n",
    "Assumed these are the true ratings & predictions results\n",
    "\n",
    "| Model A Prediction | True Ratings |\n",
    "|-------------------:|-------------:|\n",
    "| 1                  | 1            |\n",
    "| 1                  | 2            |\n",
    "| 4                  | 4            |\n",
    "| 1                  | 2            |\n",
    "| 4                  | 5            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQWBJGR6HW-1"
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "true_ratings = [1, 2, 4, 2, 5]\n",
    "model_A_pred = [1, 1, 4, 1, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFabiE8noTFO"
   },
   "source": [
    "**Measure Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAlv3oV8oTFO"
   },
   "outputs": [],
   "source": [
    "mae_low = mean_absolute_error(true_value = true_ratings,\n",
    "                              predicted_value = model_A_pred)\n",
    "\n",
    "mse_low = mean_squared_error(true_value = true_ratings,\n",
    "                             predicted_value = model_A_pred)\n",
    "\n",
    "rmse_low = root_mean_squared_error(true_value = true_ratings,\n",
    "                                   predicted_value = model_A_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtnuFLDaoTFP",
    "outputId": "7b2914a5-c48d-4ef8-8877-f78d65a25b51"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-7122a6dc-6a1b-4b62-bb8c-272259493317\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low margin of errors</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.774597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7122a6dc-6a1b-4b62-bb8c-272259493317')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-06480c44-1ccb-476d-bcd0-3065a6a07840\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06480c44-1ccb-476d-bcd0-3065a6a07840')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-06480c44-1ccb-476d-bcd0-3065a6a07840 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7122a6dc-6a1b-4b62-bb8c-272259493317 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7122a6dc-6a1b-4b62-bb8c-272259493317');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   case  MAE  MSE      RMSE\n",
       "0  Low margin of errors  0.6  0.6  0.774597"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create summary\n",
    "summary_low = pd.DataFrame({'case': ['Low margin of errors'],\n",
    "                             'MAE': [mae_low],\n",
    "                             'MSE': [mse_low],\n",
    "                             'RMSE': [rmse_low]})\n",
    "\n",
    "summary_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFcgRVrHWb2Z"
   },
   "source": [
    "In terms of low margin error case, both **MSE & MAE** results are similar same, the difference only in the RMSE due to root operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-rm7DqMYhY1"
   },
   "source": [
    "### **Conclusion**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cakeeDMEovLF",
    "outputId": "81aeff30-d69b-42d3-b149-be97124b8213"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-ce35d090-87f7-403a-9c02-252a0c1d74e7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>High margin of errors</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>3.376389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Low margin of errors</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.774597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce35d090-87f7-403a-9c02-252a0c1d74e7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-d3e7a9a4-0b2b-4437-a438-4add98223b9a\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d3e7a9a4-0b2b-4437-a438-4add98223b9a')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-d3e7a9a4-0b2b-4437-a438-4add98223b9a button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ce35d090-87f7-403a-9c02-252a0c1d74e7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ce35d090-87f7-403a-9c02-252a0c1d74e7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                    case  MAE   MSE      RMSE\n",
       "0  High margin of errors  3.0  11.4  3.376389\n",
       "0   Low margin of errors  0.6   0.6  0.774597"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((summary_high, summary_low), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DatwVLisovXU"
   },
   "source": [
    "- It's best to use RMSE / MSE when data does not contain outliers\n",
    "- use **MAE** when the data does contain outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVb1pJpwuNCV"
   },
   "source": [
    "# **3. Decision Support Metrics**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYDxq_0z43yJ"
   },
   "source": [
    "Another approach that can be used to frame reccommender problem is **consider** or recommend item based on its relevancy.\n",
    "\n",
    "Recommend most relevant item to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI91jaZUN_Vl"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/recsys_training_step.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daqZC5_oOJyf"
   },
   "source": [
    "Notion of relevance can be abstract, however we can consider relevant as :  \n",
    "- Item consumed by user\n",
    "- Item liked by the user\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "18hlcPz6O3N6"
   },
   "source": [
    "Good model performance can be regarded as \"relevant\" recommendation, most of the item recommended later will be consumed by users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiV3obx7Pikm"
   },
   "source": [
    "There are several ways to measure decision support metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RroCrtP751Us"
   },
   "source": [
    "## 3.1. Precision\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMaqfPwgPezP"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/recsys_venn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs5g_BnWSrGx"
   },
   "source": [
    "Precision goal is to maximize number of relevant recommendation from recommendation list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0IRF_qFSweR"
   },
   "source": [
    "Since our recommendation is in form N List Item,we usually measure in terms of **Precision @ K** recommended items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1A9TJ81TLKg"
   },
   "source": [
    "Let say we just trained model to recommend relevant e-commerce item to users.\n",
    "\n",
    "We want to measure how good is the model, we already splitted dataset into training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyvJ7KucTdcW"
   },
   "source": [
    "To evaluate model, we pick  from test data, one user, **UserA**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wagqr9WOT0Pc"
   },
   "source": [
    "User A has already buy some items (called as relevant item)\n",
    "\n",
    "| User A Consumed Items |\n",
    "|-----------------------|\n",
    "| Item A                |\n",
    "| Item D                |\n",
    "| Item E                |\n",
    "| Item F                |\n",
    "| Item G                |\n",
    "| Item Z                |\n",
    "| Item AA                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brVM5yBNVFSf"
   },
   "source": [
    "Model recommend top 5 relevant items  :      \n",
    "\n",
    "| Model recommended items |\n",
    "|-----------------------|\n",
    "| Item C                |\n",
    "| Item D                |\n",
    "| Item E                |\n",
    "| Item M                |\n",
    "| Item B                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbDFV2dLXlzq"
   },
   "source": [
    "we can see that from seeing the recommendation, relevant and recommended items are :     \n",
    "- Item D\n",
    "- Item E\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{precision}\n",
    "&=\n",
    "\\cfrac\n",
    "{\\text{Number of Recommended Item that are relevant}}\n",
    "{\\text{Number of Item Recommendation}} \\\\\n",
    "\\text{precision}\n",
    "&= \\cfrac{2}{5}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BAMPhGS56Bn"
   },
   "source": [
    "for easier later calculation, we will create a function to calculate precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5tdbKr9YG3F"
   },
   "outputs": [],
   "source": [
    "def precision(true_relevant, recommended_items):\n",
    "    \"\"\"Function to measure precision from given list of recommendation\"\"\"\n",
    "    # Set a counter\n",
    "    relevant_item_count = 0\n",
    "\n",
    "    # Loop all over recommendation list\n",
    "    for item in recommended_items:\n",
    "        if item in true_relevant:\n",
    "            # If in true relevant add 1\n",
    "            relevant_item_count +=1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Divide by number of recommended_items\n",
    "    precision =  relevant_item_count / len(recommended_items)\n",
    "\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8jHn_DeYwZQ"
   },
   "source": [
    "Next, we will validate the function, to calculate previous example, the function is correct if its yield **2/5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWKHlEyvY5AH"
   },
   "outputs": [],
   "source": [
    "# Sample of input data\n",
    "user_relevant_items = ['a','d','e','f','g','z','aa']\n",
    "recommendation_list = ['c','d','e','m','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTdfOOOIZN-a",
    "outputId": "d7d2192a-bf15-4038-b3db-dc1b108608b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of RecSys:  0.4\n",
      "Precision Score is equal to 2/5:  True\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision\n",
    "precision_result = precision(true_relevant = user_relevant_items,\n",
    "                             recommended_items = recommendation_list)\n",
    "\n",
    "# Print\n",
    "print('Precision of RecSys: ', precision_result)\n",
    "print('Precision Score is equal to 2/5: ', precision_result==2/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcNNCDKv83fS"
   },
   "source": [
    "## 3.2. Recall\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SNqFaSOVo0d"
   },
   "source": [
    "While precision focus on **Recomming most relevant item**, recall was the opposite, recall focuse on **Recommending as many as possible relevant items**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AlkIPCEV2bC"
   },
   "source": [
    "<center>\n",
    "<img src=\"../assets/recsys_venn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D84tvOsBAtUr"
   },
   "source": [
    "What do we observed?\n",
    "- There are song that sang by multiple artists\n",
    "- There are song that have similar `artists`, `album_name`, `track_name`, and `track_genre`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLOrViOyZ2cm"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wb9Nk5fZ2rn"
   },
   "source": [
    "Since our recommendation is in form N List Item,we usually measure in terms of **Recall @ K** recommended items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY0Vs3ssZ2rn"
   },
   "source": [
    "Let say we just trained model to recommend relevant e-commerce item to users.\n",
    "\n",
    "We want to measure how good is the model, we already splitted dataset into training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMB4GhKSZ2ro"
   },
   "source": [
    "To evaluate model, we pick  from test data, one user, **UserA**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DhWb_fgZ2ro"
   },
   "source": [
    "User A has already buy some items (called as relevant item)\n",
    "\n",
    "| User A Consumed Items |\n",
    "|-----------------------|\n",
    "| Item A                |\n",
    "| Item D                |\n",
    "| Item E                |\n",
    "| Item F                |\n",
    "| Item G                |\n",
    "| Item Z                |\n",
    "| Item AA                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLfZor-fZ2ro"
   },
   "source": [
    "Model recommend top 5 relevant items  :      \n",
    "\n",
    "| Model recommended items |\n",
    "|-----------------------|\n",
    "| Item C                |\n",
    "| Item D                |\n",
    "| Item E                |\n",
    "| Item M                |\n",
    "| Item B                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5Ckvst5Z2ro"
   },
   "source": [
    "we can see that from seeing the recommendation , relevant and recommended items are :     \n",
    "- Item D\n",
    "- Item E\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{recall}\n",
    "&=\n",
    "\\cfrac\n",
    "    {\\text{Number of Recommended Item that are relevant}}\n",
    "    {\\text{Number of Relevant Item}} \\\\\n",
    "\\text{recall}\n",
    "&= \\cfrac{2}{7}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oq-_mSJtdN9i"
   },
   "source": [
    "Now, lets create python function to measure recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nEEFq0dZ_DE"
   },
   "outputs": [],
   "source": [
    "def recall(true_relevant, recommended_items):\n",
    "    \"\"\"Function to measure recall from given list of recommendation\"\"\"\n",
    "    # Set a counter\n",
    "    relevant_item_count = 0\n",
    "\n",
    "    # loop all over recommendation list\n",
    "    for item in recommended_items:\n",
    "        if item in true_relevant:\n",
    "            # if in true relevant add 1\n",
    "            relevant_item_count +=1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # divide by number of relevant items\n",
    "    recall  =  relevant_item_count / len(true_relevant)\n",
    "\n",
    "    return recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajFeGogodMhm"
   },
   "source": [
    "Next, we will validate the function, to calculate previous example, the function is correct if its yield **2/7**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m3pT9XNkdMhs"
   },
   "outputs": [],
   "source": [
    "user_relevant_items = ['a','d','e','f','g','z','aa']\n",
    "recommendation_list = ['c','d','e','m','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cov_PyoEdMht",
    "outputId": "03838322-a99c-448c-efc9-09c472e308f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of Recsys:  0.2857142857142857\n",
      "Recall Score is equal to 2/7 :  True\n"
     ]
    }
   ],
   "source": [
    "recall_result = recall(true_relevant = user_relevant_items,\n",
    "                       recommended_items = recommendation_list)\n",
    "\n",
    "print('Recall of Recsys: ', recall_result)\n",
    "print('Recall Score is equal to 2/7 : ',recall_result==2/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7R1EIS1ZOlU"
   },
   "source": [
    "## 3.3. Balancing Precision & Recall: F1 Score\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXAmZT2ld1uQ"
   },
   "source": [
    "Previously we have learn how to measure both **Precision and Recall**, to recap :     \n",
    "\n",
    "- Precision focus on returning most relevant stuff\n",
    "- Recall focus on gathering as many as possible relevant item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D8S4Jzoeoz5"
   },
   "source": [
    "Umm, what if we concern about both ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtO4X_ydZpxp"
   },
   "source": [
    "The simplest way to balance both measure , we can use **average**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb73lze1fY8G"
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\text{average of precision and recall}\n",
    "&= \\cfrac{1}{2}(\\text{precision} + \\text{recall})\\\\\n",
    "\\text{average of precision and recall}\n",
    "&= \\cfrac{1}{2}\n",
    "    \\left (\n",
    "        \\cfrac{\\text{Number of Recommended Item that are relevant}}{\\text{Number of Item Recommendation}}\n",
    "        +\n",
    "        \\cfrac{\\text{Number of Recommended Item that are relevant}}{\\text{Number of Relevant Item}}\n",
    "    \\right )\n",
    "\\end{align*}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NICW4fHjgiJK"
   },
   "source": [
    "However, we cannot directly divide by **arithmetic mean** above since precision and recall has different denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtHw3ifegt6Y"
   },
   "source": [
    "We can use **harmonic mean**\n",
    "\n",
    "$$\n",
    "\\text{Harmonic mean}\n",
    "=\n",
    "\\cfrac\n",
    "{N}\n",
    "{\\cfrac{1}{x_{1}} + \\dots + \\cfrac{1}{x_{N}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAtO7UxFtid1"
   },
   "source": [
    "So in our case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DZGl0C6tluy"
   },
   "source": [
    "$$\n",
    "\\text{average of precision and recall}\n",
    "=\n",
    "\\cfrac\n",
    "{2}\n",
    "{\\cfrac{1}{\\text{precision}} + \\cfrac{1}{\\text{recall}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4gynQkyi4i0"
   },
   "source": [
    "Mean of Precision and Recall called as an **F1-Score**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{F1-score}\n",
    "&=\n",
    "\\cfrac\n",
    "{2}\n",
    "{\\cfrac{1}{\\text{precision}} + \\cfrac{1}{\\text{recall}}} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{2}\n",
    "{\\cfrac{\\text{precision} + \\text{recall}}{\\text{precision} \\cdot \\text{recall}}} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac{2 (\\text{precision} \\cdot \\text{recall})}{\\text{precision} + \\text{recall}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWWuIyVXk9RB"
   },
   "source": [
    "We will try on the same example from precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AaL_OH1lDVT"
   },
   "outputs": [],
   "source": [
    "user_relevant_items = ['a','d','e','f','g','z','aa']\n",
    "recommendation_list = ['c','d','e','m','b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fiDY-7OuwJ8"
   },
   "source": [
    "Previously\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{precision} &= \\cfrac{2}{5} \\\\\n",
    "\\text{recall} &= \\cfrac{2}{7}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1zLMP6zmA1x"
   },
   "source": [
    "Thus, the F1-score would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ0oO-8tmJJ8"
   },
   "source": [
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{F1-score}\n",
    "&=\n",
    "\\cfrac{2 (\\text{precision} \\cdot \\text{recall})}{\\text{precision} + \\text{recall}} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac{2(\\frac{2}{5}*\\frac{2}{7})}{\\frac{2}{5} + \\frac{2}{7}} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac{\\frac{8}{35}}{\\frac{24}{35}} \\\\\n",
    "&=\n",
    "\\cfrac{8}{24} \\\\\n",
    "&=0.33\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBBfpwlEjnpr"
   },
   "source": [
    "for easier usage, we will create python function to measure **f1 score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgkzuu_5fXF9"
   },
   "outputs": [],
   "source": [
    "def f1_score(true_relevant, recommended_items) :\n",
    "    \"\"\"Function to measure f1 score from precision and recall\"\"\"\n",
    "    # calling precision function\n",
    "    precision_result = precision(true_relevant = true_relevant,\n",
    "                                 recommended_items = recommended_items)\n",
    "\n",
    "    # calling recall function\n",
    "    recall_result = recall(true_relevant = true_relevant,\n",
    "                           recommended_items = recommended_items)\n",
    "\n",
    "    # calculate numerator\n",
    "    numerator = 2 * (precision_result*recall_result)\n",
    "\n",
    "    #calculate denominator\n",
    "    denominator = (precision_result + recall_result)\n",
    "\n",
    "    f1 = numerator / denominator\n",
    "\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdcrq710kddR"
   },
   "source": [
    "Time to validate the function,we will use previous example, the function is valid if the result is equal to **8/24**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XiQSO406ky7W",
    "outputId": "91f2b33b-aae7-4b5f-b71b-e396a7111d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of Recsys:  0.3333333333333333\n",
      "F1 Score is equal to 8/14 :  True\n"
     ]
    }
   ],
   "source": [
    "f1_result = f1_score(true_relevant = user_relevant_items,\n",
    "                     recommended_items = recommendation_list)\n",
    "\n",
    "\n",
    "print('F1 score of Recsys: ', f1_result)\n",
    "print('F1 Score is equal to 8/14 : ',f1_result==8/24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MtFdQC2JEqL"
   },
   "source": [
    "# **4. Rank Aware Top N Metrics**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2YXOZ-Csitr"
   },
   "source": [
    "## 4.1. Introduction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EO7ZhaWq4I1"
   },
   "source": [
    "- Previously we consider recommendation task as recommending relevant item (binary, relevant or irrelevant)\n",
    "- However we might have intuition that everyone has limited time to watch / consume item\n",
    "- Even though recommended items are relevant item the users will **prioritize** most relevant item first\n",
    "- Priority itself has **ordered manner** or **rankings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7N88Y-iTtxh6"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/item_importancce.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeDfQABSsGq0"
   },
   "source": [
    "However, decision metrics doesnot capture model performance based on ranking or orderings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxvTSnQRUaQO"
   },
   "source": [
    "We need other measurement that account ranking / ordering.\n",
    "\n",
    "Some metrics we can use :     \n",
    "- Mean Average Precision\n",
    "- Discounted Cumulative Gain + Normalized Discounted Cumulative Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aj4M_XDcpuKd"
   },
   "source": [
    "## 4.2. Mean Average Precision\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRG3PqaGV-7D"
   },
   "source": [
    "Previously in **Decision Support Metrics** we learn about **precision**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xa_d8W6-WFTa"
   },
   "source": [
    "However the precision only measure relevancy percentage on all recommendation list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RhVEBE3WL5a"
   },
   "source": [
    "to account ranking we can use some sort of **rolling precision** toward each ranking level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpxkDVjMZCE3"
   },
   "source": [
    "<center>\n",
    "\n",
    "<img src=\"../assets/evaluation_matrix_relevance.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zs-BYv95arui"
   },
   "source": [
    "and we will average **precision** from each position, that was called as **Average Precision**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjbbTfjMgo3b"
   },
   "source": [
    "$$\n",
    "\\text{Average Precision @ K} =\n",
    "\\cfrac{1}{K}\n",
    "\\sum_{i=1}^{K} \\ \\text{Precision @ K=i}\n",
    "$$\n",
    "\n",
    "with :     \n",
    "- $K$ = number of recommended items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvLVqVr3hvdi"
   },
   "source": [
    "Average Precision only measure at 1 user recommendation only, and does not capture overall model performance, hence we need to add more average term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgJi5CyEh4se"
   },
   "source": [
    "$$\n",
    "\\text{Mean Average Precision}\n",
    "=\n",
    "\\cfrac{1}{\\text{Number of U}} \\\n",
    "\\sum_{u \\in U} \\text{Average Precision(u)}\n",
    "$$\n",
    "\n",
    "with :     \n",
    "- $U$ = all users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZHxb-WbaaJ2"
   },
   "source": [
    "To demonstrate we will use example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zFg_a1samew"
   },
   "source": [
    "User A has already buy some items (called as relevant item)\n",
    "\n",
    "| User A Consumed Items |\n",
    "|-----------------------|\n",
    "| Item A                |\n",
    "| Item D                |\n",
    "| Item E                |\n",
    "| Item F                |\n",
    "| Item G                |\n",
    "| Item Z                |\n",
    "| Item AA                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZB_tyv6famew"
   },
   "source": [
    "Model recommend top 5 relevant items  :      \n",
    "\n",
    "| Model recommended items |\n",
    "|-----------------------|\n",
    "| Item C                |\n",
    "| Item D                |\n",
    "| Item E                |\n",
    "| Item M                |\n",
    "| Item B                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SB9zxgzGpzyJ"
   },
   "outputs": [],
   "source": [
    "user_relevant_items = ['a','d','e','f','g','z','aa']\n",
    "recommendation_list = ['c','d','e','m','b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxT0_P0IaySc"
   },
   "source": [
    "Since we are having **Top 5** Recommendation we will measure precision till 5th position item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT9AzD75a9SD"
   },
   "source": [
    "| Model recommended items | Relevant ?  |\n",
    "|:-----------------------:|-------------|\n",
    "| Item C                  |     No        |\n",
    "| Item D                  |        Yes     |\n",
    "| Item E                  |         Yes    |\n",
    "| Item M                  |          No   |\n",
    "| Item B                  |          No   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vb8bwKuMbgOC"
   },
   "source": [
    "---\n",
    "**$1^{st} \\text{ position Precision}$**\n",
    "\n",
    "relevant item :     None\n",
    "\n",
    "**$$1^{st} \\text{ position Precision} = 0/1$$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8NmILxBcDmx"
   },
   "source": [
    "---\n",
    "**$2^{nd} \\text{ position Precision}$**\n",
    "\n",
    "relevant item :   \n",
    "1. Item D\n",
    "\n",
    "**$$2^{nd} \\text{ position Precision} = 1/2$$**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2XwxfzdcNOB"
   },
   "source": [
    "---\n",
    "**$3^{rd} \\text{ position Precision}$**\n",
    "\n",
    "relevant item :   \n",
    "1. Item D\n",
    "2. Item E\n",
    "\n",
    "**$$3^{rd} \\text{ position Precision} = 2/3$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JukVVBtmchtM"
   },
   "source": [
    "---\n",
    "**$4^{th} \\text{ position Precision}$**\n",
    "\n",
    "relevant item :   \n",
    "1. Item D\n",
    "2. Item E\n",
    "\n",
    "**$$4^{th} \\text{ position Precision} = 2/4$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfykRDh5crlQ"
   },
   "source": [
    "---\n",
    "**$5^{th} \\text{ position Precision}$**\n",
    "\n",
    "relevant item :   \n",
    "1. Item D\n",
    "2. Item E\n",
    "\n",
    "**$$5^{th} \\text{ position Precision} = 2/5$$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnklplvvcvNx"
   },
   "source": [
    "---\n",
    "Finally,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Average Precision @5}\n",
    "&= \\cfrac{1}{5} \\left( \\cfrac{0}{1} + \\cfrac{1}{2} + \\cfrac{2}{3} + \\cfrac{2}{4} + \\cfrac{2}{5} \\right) \\\\\n",
    "&= 0.41333\\dots\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_Hc4KgPdntx"
   },
   "source": [
    "for easier usage we will create function to compute average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sKf91TCEzMq-",
    "outputId": "daa7c2bf-13c1-43e8-e563-baa530ff623b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a'] ['c'] 0.0\n",
      "['a', 'd'] ['c', 'd'] 0.5\n",
      "['a', 'd', 'e'] ['c', 'd', 'e'] 0.6666666666666666\n",
      "['a', 'd', 'e', 'f'] ['c', 'd', 'e', 'm'] 0.5\n",
      "['a', 'd', 'e', 'f', 'g'] ['c', 'd', 'e', 'm', 'b'] 0.4\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "k=5\n",
    "for position in range(k):\n",
    "    item_at_pos = user_relevant_items[:position+1]\n",
    "    pred_at_pos = recommendation_list[:position+1]\n",
    "\n",
    "    prec_at_pos = precision(true_relevant = item_at_pos,\n",
    "                            recommended_items = pred_at_pos)\n",
    "    print(item_at_pos, pred_at_pos, prec_at_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpP-NC-I5WmJ"
   },
   "outputs": [],
   "source": [
    "def average_precision(true_relevant, recommended_items, k):\n",
    "    \"\"\"Function to measure average precision @ k\"\"\"\n",
    "    # Create empty list to store precision calculation\n",
    "    precisions = []\n",
    "\n",
    "    # Iterate loop over number of k\n",
    "    for position in range(k) :\n",
    "        # Slice item & predictions at position, we need to add +1 in position\n",
    "        item_at_pos = true_relevant[:position+1]\n",
    "        pred_at_pos = recommended_items[:position+1]\n",
    "\n",
    "        # Call precision\n",
    "        p_at_pos = precision(true_relevant = item_at_pos,\n",
    "                             recommended_items = pred_at_pos)\n",
    "\n",
    "        # Append precision at pos\n",
    "        precisions.append(p_at_pos)\n",
    "\n",
    "    # Average precision\n",
    "    average_precision = np.mean(precisions)\n",
    "\n",
    "    return average_precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-5ipDlteyqO"
   },
   "source": [
    "Now, its time to validate our function, if its correct it should yield **0.4133333333333333**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuqw5c7jp1rQ",
    "outputId": "a8b0ebb9-fdb1-4e3f-e0f5-e750cbe36281"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP @ 5 score: 0.4133333333333333\n",
      "AP @ 5 is equal to 0.413... : True\n"
     ]
    }
   ],
   "source": [
    "# Calculate the AP @ 5\n",
    "ap_5 = average_precision(true_relevant = user_relevant_items,\n",
    "                         recommended_items = recommendation_list,\n",
    "                         k = 5)\n",
    "\n",
    "print('AP @ 5 score:', ap_5)\n",
    "print('AP @ 5 is equal to 0.413... :', ap_5 == 0.4133333333333333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnCrPkzcgRie"
   },
   "source": [
    "Our function is valid!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwCEqGdEp2VM"
   },
   "source": [
    "## 4.3. Discounted Cumulative Gain\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8aTqevf2idwg"
   },
   "source": [
    "Previously we know that **Mean Average Precision** try to calculate precision of each level, However there are some limitations :      \n",
    "- MAP only measure rolling average precision\n",
    "- If we find relevant item in upper position we will get better result (lower denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKoKyK9Ui4FI"
   },
   "source": [
    "Is there another way to approach ranking ? some ideas may be :    \n",
    "- Give Different Scoring to each position\n",
    "- Since we only care upper item\n",
    "- We give higher score to upper item (if correctly ordered) and lower score to lower position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnSGWJzMj4rc"
   },
   "source": [
    "<center>\n",
    "<img src=\"../assets/item_score_relevance.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lW2utkC-kHLo"
   },
   "source": [
    "That was the idea of **Discounted Cumulative Gain** or DCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLXP8rixkMuQ"
   },
   "source": [
    "$$\n",
    "DCG @ k\n",
    "=\n",
    "\\sum_{i=1}^{k}\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}}-1}\n",
    "{\\log_{2}(i + 2)}\n",
    "$$\n",
    "\n",
    "with :     \n",
    "- $\\text{rel}_{i}$ : Relevance Score if item at $i^{th}$ correctly ranked\n",
    "- Relevance score could be resulted from any scoring function\n",
    "- Simple example, if correctly predicted **relevance score=1** otherwise **0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivdkGvamle0Z"
   },
   "source": [
    "To demonstrate we will use example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuABk6kWmV0S"
   },
   "source": [
    "We will use sample of test set, based on that we will take user A as example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkk1uFhCle0a"
   },
   "source": [
    "User A has already listened to many songs, some songs are played many times the order based on most played song are :\n",
    "\n",
    "| User A Most Listened Songs |\n",
    "|-----------------------|\n",
    "| Song A                |\n",
    "| Song B                |\n",
    "| Song D               |\n",
    "| Song E               |\n",
    "| Song Z               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqLTQ17sle0a"
   },
   "source": [
    "Model recommend top 5 relevant items  :      \n",
    "\n",
    "| Model recommended items |\n",
    "|-----------------------|\n",
    "| Song A                |\n",
    "| Song C                |\n",
    "| Song D               |\n",
    "| Song M               |\n",
    "| Song Z               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW_tVcz8li5d"
   },
   "source": [
    "for this example, we will use relevance score :    \n",
    "- **1** if ranking is correct\n",
    "- **0** if incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEYUPYp9le0a"
   },
   "outputs": [],
   "source": [
    "user_item_rank = ['a','b','d','e','z']\n",
    "recommendation_list = ['a','c','d','m','z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6SB2FR3ngVp"
   },
   "source": [
    "we will calculate manually first two items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMzwvhxFnq1X"
   },
   "source": [
    "---\n",
    "**$1^{\\text{st}}$ position**\n",
    "\n",
    "$$\n",
    "i^{\\text{th}}DCG\n",
    "=\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}}-1}\n",
    "{\\log_{2}(i + 2)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJeEIpGf8OPL"
   },
   "source": [
    "<center>\n",
    "\n",
    "| No | User A Most Listened Songs | Model recommended items | Relevance Score |\n",
    "|:--|:--|:--|--:|\n",
    "| 1 | Song A | Song A | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1y0Vrx_8gji"
   },
   "source": [
    "- Item A (Correctly Predicted Rank), thus score = 1\n",
    "- with $i=1$, thus\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "1^{\\text{st}}DCG\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}}-1}\n",
    "{\\log_{2}(i + 2)} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{1}-1}\n",
    "{\\log_{2}(1 + 2)} \\\\ \\\\\n",
    "1^{\\text{st}}DCG\n",
    "&= \\cfrac{1}{1.58} \\approx 0.63\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GmWm_Ze9pRX"
   },
   "source": [
    "---\n",
    "**$2^{\\text{nd}}$ position**\n",
    "\n",
    "$$\n",
    "i^{\\text{th}}DCG\n",
    "=\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}-1}}\n",
    "{\\log_{2}(i + 2)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8I0znsd9pRg"
   },
   "source": [
    "<center>\n",
    "\n",
    "| No | User A Most Listened Songs | Model recommended items | Relevance Score |\n",
    "|:--|:--|:--|--:|\n",
    "| 1 | Song A | Song A | 1 |\n",
    "| 2 | Song B | Song C | 0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhp2cGD09pRh"
   },
   "source": [
    "- Item C (incorrectly predicted Rank), thus score = 0\n",
    "- with $i=2$, thus\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "2^{\\text{nd}}DCG\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}}-1}\n",
    "{\\log_{2}(i + 2)} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{0}-1}\n",
    "{\\log_{2}(2 + 2)} \\\\ \\\\\n",
    "2^{\\text{nd}}DCG\n",
    "&= \\cfrac{0}{2} = 0.0\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQmt87rCArDo"
   },
   "source": [
    "---\n",
    "Finally, if we want to caculate the k-th DCG, thus\n",
    "\n",
    "$$\n",
    "DCG @ k\n",
    "=\n",
    "\\sum_{i=1}^{k}\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}}-1}\n",
    "{\\log_{2}(i + 2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJVKf3FlA68s"
   },
   "source": [
    "<center>\n",
    "\n",
    "| No | User A Most Listened Songs | Model recommended items | Relevance Score |\n",
    "|:--|:--|:--|--:|\n",
    "| 1 | Song A | Song A | 1 |\n",
    "| 2 | Song B | Song C | 0 |\n",
    "| 3 | Song D | Song D | 1 |\n",
    "| 4 | Song E | Song M | 0 |\n",
    "| 5 | Song Z | Song Z | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wrpsay_CBEvk"
   },
   "source": [
    "With $k=5$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "DCG @ 5\n",
    "&=\n",
    "\\sum_{i=1}^{k}\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}}-1}\n",
    "{\\log_{2}(i + 2)}\\\\ \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{1}}-1}\n",
    "{\\log_{2}(1 + 2)}\n",
    "+\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{2}}-1}\n",
    "{\\log_{2}(2 + 2)}\n",
    "+ \\dots +\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{5}}-1}\n",
    "{\\log_{2}(5 + 2)} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{1}-1}\n",
    "{\\log_{2}(1 + 2)}\n",
    "+\n",
    "\\cfrac\n",
    "{2^{0}-1}\n",
    "{\\log_{2}(2 + 2)}\n",
    "+ \\dots +\n",
    "\\cfrac\n",
    "{2^{1}-1}\n",
    "{\\log_{2}(5 + 2)} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac{2-1}{\\log_{2}(3)}\n",
    "+\n",
    "\\cfrac{1-1}{\\log_{2}(4)}\n",
    "+ \\dots +\n",
    "\\cfrac{2-1}{\\log_{2}(7)} \\\\ \\\\\n",
    "DCG @ 5\n",
    "&= 1.418\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0QjhmrvnmuL"
   },
   "source": [
    "We create a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6Qw89UCDi37"
   },
   "outputs": [],
   "source": [
    "def dcg(true_item, predicted_item, k):\n",
    "    \"\"\"Function to calculate DCG @ k\"\"\"\n",
    "    # Create a store\n",
    "    dcgs = []\n",
    "\n",
    "    # iterate over the k\n",
    "    for position in range(k):\n",
    "        # Obtain relevance of item at position\n",
    "        rel_pos = true_item[position] == predicted_item[position]\n",
    "\n",
    "        # Calculate pos-th DCG\n",
    "        dcg_pos = ((2**rel_pos)-1) / (np.log2(position+1 + 2))\n",
    "\n",
    "        # Append to dcgs\n",
    "        dcgs.append(dcg_pos)\n",
    "\n",
    "    # Calculate the sum of DCG at every position\n",
    "    score = np.sum(dcgs)\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRKeukFCFDKX",
    "outputId": "fa1d3b59-993a-4866-ed7a-eef7a4df81b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG @ 5 results:  1.4178134987528728\n",
      "DCG @ 5 results = 1.418 True\n"
     ]
    }
   ],
   "source": [
    "# Calculate the DCG\n",
    "dcg_result = dcg(true_item = user_item_rank,\n",
    "                 predicted_item = recommendation_list,\n",
    "                 k = 5)\n",
    "\n",
    "print('DCG @ 5 results: ', dcg_result)\n",
    "print('DCG @ 5 results = 1.418', dcg_result==1.4178134987528728)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jerAY4BOp7yN"
   },
   "source": [
    "## 4.4. Normalized Discounted Cumulative Gain\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jax2UWRmxJYV"
   },
   "source": [
    "Previously its hard to interpret **Discounted Cumulative Gain** directly, however there is a solution :     \n",
    "- Since we held the true ranking, we can estimate how much **DCG** score if it ranked correctly\n",
    "- If we divide by those, our DCG score now range from 0 to 1 (all item ranked correctly)\n",
    "- It was the idea of **Normalized Discounted Cumulative Gain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XQvh21MyGtc"
   },
   "source": [
    "$$\n",
    "\\text{Normalized DCG}\n",
    "=\n",
    "\\cfrac\n",
    "{\\text{DCG}}\n",
    "{\\text{Ideal DCG}}\n",
    "$$\n",
    "\n",
    "with :      \n",
    "- Ideal DCG : DCG using true rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3iJbCJ48HZu7"
   },
   "source": [
    "Using the previous example, in ideal DCG all the relevance scores are equal to 1.0, thus\n",
    "\n",
    "With $k=5$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Ideal } DCG @ 5\n",
    "&=\n",
    "\\sum_{i=1}^{k}\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{i}}-1}\n",
    "{\\log_{2}(i + 2)}\\\\ \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{1}}-1}\n",
    "{\\log_{2}(1 + 2)}\n",
    "+\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{2}}-1}\n",
    "{\\log_{2}(2 + 2)}\n",
    "+ \\dots +\n",
    "\\cfrac\n",
    "{2^{\\text{rel}_{5}}-1}\n",
    "{\\log_{2}(5 + 2)} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{2^{1}-1}\n",
    "{\\log_{2}(1 + 2)}\n",
    "+\n",
    "\\cfrac\n",
    "{2^{1}-1}\n",
    "{\\log_{2}(2 + 2)}\n",
    "+ \\dots +\n",
    "\\cfrac\n",
    "{2^{1}-1}\n",
    "{\\log_{2}(5 + 2)} \\\\ \\\\\n",
    "&=\n",
    "\\cfrac{2-1}{\\log_{2}(3)}\n",
    "+\n",
    "\\cfrac{2-1}{\\log_{2}(4)}\n",
    "+ \\dots +\n",
    "\\cfrac{2-1}{\\log_{2}(7)} \\\\ \\\\\n",
    "\\text{Ideal } DCG @ 5\n",
    "&= 2.304666 \\approx 2.305\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bW-0NGoNH-vw"
   },
   "source": [
    "After that, we can calculate the normalized DCG\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Normalized DCG}\n",
    "&=\n",
    "\\cfrac\n",
    "{\\text{DCG}}\n",
    "{\\text{Ideal DCG}} \\\\\n",
    "&=\n",
    "\\cfrac\n",
    "{1.418}\n",
    "{2.305} \\\\\n",
    "\\text{Normalized DCG}\n",
    "&\\approx 0.6152\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqy12BMEz2uB"
   },
   "source": [
    "Now, we will create function to measure **NDCG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyfJSSYez7A6"
   },
   "outputs": [],
   "source": [
    "def ndcg(true_item, predicted_item, k) :\n",
    "    \"\"\"Function to calculate the normalized dcg @ k\"\"\"\n",
    "    # Calculate DCG @ K\n",
    "    dcg_result = dcg(true_item = true_item,\n",
    "                     predicted_item = predicted_item,\n",
    "                     k = k)\n",
    "\n",
    "    # Calculate ideal DCG @ k\n",
    "    idcg_result = dcg(true_item = true_item,\n",
    "                      predicted_item = true_item,\n",
    "                      k = k)\n",
    "\n",
    "    # Normalize the DCG\n",
    "    ndcg_result = dcg_result/idcg_result\n",
    "\n",
    "    return ndcg_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joXVXjU20bE5",
    "outputId": "2fcfad70-f061-47d0-809f-03af794f56fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized DCG @ 5 results:  0.6151925313740475\n",
      "Normalized DCG @ 5 results = 0.6152? True\n"
     ]
    }
   ],
   "source": [
    "# Calculate the nDCG\n",
    "ndcg_result = ndcg(true_item = user_item_rank,\n",
    "                   predicted_item = recommendation_list,\n",
    "                   k = 5)\n",
    "\n",
    "print('Normalized DCG @ 5 results: ', ndcg_result)\n",
    "print('Normalized DCG @ 5 results = 0.6152?', ndcg_result==0.6151925313740475)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqjZ3Npe0qRA"
   },
   "source": [
    "Voila, our function working properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yzfSj_lqAU5"
   },
   "source": [
    "## 4.5. Comparison\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH8TwtxB0s2_"
   },
   "source": [
    "Previously we have learn some metrics related with ranking, now we will experiment to know more about each metrics characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WERA4ktq1KD-"
   },
   "source": [
    "### Experiment Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS6Q5YOWwWda"
   },
   "source": [
    "- We will compare two model in terms of ranking item in recommendation (Model A & B)\n",
    "- Recommendation will be in 5 item list / rank\n",
    "- We will take sample from test set (assumed) , recommendation on user A item preference (truth)\n",
    "- Metrics we will compare is **NDCG** and **MAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2kVW5iwh1lo_"
   },
   "source": [
    "| User Truth Preference  | Model A Item Recommendation (Ordered) | Model B Item Recommendation (Ordered) |\n",
    "|:----------------------:|---------------------------------------|---------------------------------------|\n",
    "| Song A                 | Song A                                | Song B                                |\n",
    "| Song C                 | Song C                                | Song M                                |\n",
    "| Song D                 | Song D                                | Song D                                |\n",
    "| Song M                 | Song K                                | Song K                                |\n",
    "| Song Z                 | Song M                                | Song Y                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jA-7KZm62oxd"
   },
   "source": [
    "- Both model correctly predict two items\n",
    "- However, model A predict upper ranked items better than model B\n",
    "- Ideally we want metrics such that model A > model B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfZ6CFiBqCKf"
   },
   "outputs": [],
   "source": [
    "user_a_true_ordering = ['a','c','d','m','z']\n",
    "model_a_ordering = ['a','c','d','k','m']\n",
    "model_b_ordering = ['b','m','d','k','y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZoNCZnw3i7X"
   },
   "source": [
    "### Average Precision (MAP)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIyBzlzV2kr_"
   },
   "outputs": [],
   "source": [
    "# Calculate mean average precision model A\n",
    "model_a_map = average_precision(true_relevant = user_a_true_ordering,\n",
    "                                recommended_items = model_a_ordering,\n",
    "                                k = 5)\n",
    "\n",
    "# Calculate mean average precision model B\n",
    "model_b_map = average_precision(true_relevant = user_a_true_ordering,\n",
    "                                recommended_items = model_b_ordering,\n",
    "                                k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QReAMkEy3XXT",
    "outputId": "9fae97c6-38bc-4e66-bd08-78657cd2e359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@5 model A              : 0.9099999999999999\n",
      "MAP@5 model B              : 0.24666666666666667\n",
      "Does model A better than B ? True\n"
     ]
    }
   ],
   "source": [
    "print('MAP@5 model A              :', model_a_map)\n",
    "print('MAP@5 model B              :', model_b_map)\n",
    "print('Does model A better than B ?', model_a_map > model_b_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qVpXfsw3lhV"
   },
   "source": [
    "### NDCG\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw11x4E63pji"
   },
   "outputs": [],
   "source": [
    "# Calculate the normalized DCG\n",
    "model_a_ndcg = ndcg(true_item = user_a_true_ordering,\n",
    "                    predicted_item = model_a_ordering,\n",
    "                    k = 5)\n",
    "\n",
    "model_b_ndcg = ndcg(true_item = user_a_true_ordering,\n",
    "                    predicted_item = model_b_ordering,\n",
    "                    k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76h-nVBf3pji",
    "outputId": "517130cd-b7d4-42ba-a1b6-23f8b24c6b0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 model A             : 0.6775845629312456\n",
      "NDCG@5 model B             : 0.18687154706714618\n",
      "Does model A better than B ? True\n"
     ]
    }
   ],
   "source": [
    "print('NDCG@5 model A             :', model_a_ndcg)\n",
    "print('NDCG@5 model B             :', model_b_ndcg)\n",
    "print('Does model A better than B ?', model_a_ndcg > model_b_ndcg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDCInvyNK3lm"
   },
   "source": [
    "Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "_Zrj0NIgK4m4",
    "outputId": "b75d9db6-7f8e-4e4f-f76d-5a4fb065225d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "  <div id=\"df-f3020850-31ee-44da-a2fa-95d7279d63f3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAP/AP</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>is A better than B?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.677585</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.186872</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3020850-31ee-44da-a2fa-95d7279d63f3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "\n",
       "\n",
       "\n",
       "    <div id=\"df-681793d5-f237-4e7a-bbba-3bbbe882ec66\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-681793d5-f237-4e7a-bbba-3bbbe882ec66')\"\n",
       "              title=\"Suggest charts.\"\n",
       "              style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "    </div>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "    background-color: #E8F0FE;\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: #1967D2;\n",
       "    height: 32px;\n",
       "    padding: 0 0 0 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: #E2EBFA;\n",
       "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: #174EA6;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "    background-color: #3B4455;\n",
       "    fill: #D2E3FC;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart:hover {\n",
       "    background-color: #434B5C;\n",
       "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "    fill: #FFFFFF;\n",
       "  }\n",
       "</style>\n",
       "\n",
       "    <script>\n",
       "      async function quickchart(key) {\n",
       "        const containerElement = document.querySelector('#' + key);\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      }\n",
       "    </script>\n",
       "\n",
       "      <script>\n",
       "\n",
       "function displayQuickchartButton(domScope) {\n",
       "  let quickchartButtonEl =\n",
       "    domScope.querySelector('#df-681793d5-f237-4e7a-bbba-3bbbe882ec66 button.colab-df-quickchart');\n",
       "  quickchartButtonEl.style.display =\n",
       "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "}\n",
       "\n",
       "        displayQuickchartButton(document);\n",
       "      </script>\n",
       "      <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f3020850-31ee-44da-a2fa-95d7279d63f3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f3020850-31ee-44da-a2fa-95d7279d63f3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "         MAP/AP      NDCG  is A better than B?\n",
       "Model                                         \n",
       "A      0.910000  0.677585                 True\n",
       "B      0.246667  0.186872                 True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'Model': ['A', 'B'],\n",
    "        'MAP/AP': [model_a_map, model_b_map],\n",
    "        'NDCG': [model_a_ndcg, model_b_ndcg],\n",
    "        'is A better than B?': [model_a_map>model_b_map,\n",
    "                                model_a_ndcg>model_b_ndcg]\n",
    "    },\n",
    ").set_index('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rp-5iyYh4vLz"
   },
   "source": [
    "Both measurement yield the same result, model A > model B, however there are some notes :      \n",
    "- MAP / AP Measure is bigger than NDCG, the measure quite optimistic\n",
    "- NDCG scale are lower because instead of predicting relevancy it should predict rank correctly"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YUl2Q9jlSLBg",
    "4UbxpDTqMjwD",
    "UxpX-m6jL41l",
    "FGYwGmlAd7v2",
    "gC_lBHu_hpQs",
    "j9RLlMPrhrkk",
    "W9wihLpzht1-",
    "PVVUsYN44xBr",
    "0DX3SIpR6yJw",
    "R86jaUsc8QX8",
    "srF7JKDDFAux",
    "X-rm7DqMYhY1",
    "VVb1pJpwuNCV",
    "RroCrtP751Us",
    "BcNNCDKv83fS",
    "D7R1EIS1ZOlU",
    "4MtFdQC2JEqL",
    "O2YXOZ-Csitr",
    "aj4M_XDcpuKd",
    "AwCEqGdEp2VM",
    "jerAY4BOp7yN",
    "1yzfSj_lqAU5",
    "WERA4ktq1KD-",
    "CZoNCZnw3i7X",
    "9qVpXfsw3lhV"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
